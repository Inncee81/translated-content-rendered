---
title: MediaStreamAudioSourceNode
slug: Web/API/MediaStreamAudioSourceNode
tags:
  - API
  - MediaStreamAudioSourceNode
  - Web Audio API
translation_of: Web/API/MediaStreamAudioSourceNode
---
<p></p><section class="Quick_links" id="Quick_Links"><ol><li><strong><a href="/es/docs/Web/API/Web_Audio_API">Web Audio API</a></strong></li><li><strong><a href="/es/docs/Web/API/MediaStreamAudioSourceNode"><code>MediaStreamAudioSourceNode</code></a></strong></li><li class="toggle"><details open><summary>Constructor</summary><ol><li><a href="/es/docs/Web/API/MediaStreamAudioSourceNode/MediaStreamAudioSourceNode"><code>MediaStreamAudioSourceNode()</code></a> <a style="opacity: 0.5;" href="/es/docs/Web/API/MediaStreamAudioSourceNode/MediaStreamAudioSourceNode$translate">[Traducir]</a></li></ol></details></li><li class="toggle"><details open><summary>Herencia</summary><ol><li><a href="/es/docs/Web/API/AudioNode"><code>AudioNode</code></a></li><li><a href="/es/docs/Web/API/EventTarget"><code>EventTarget</code></a></li></ol></details></li><li class="toggle"><details open><summary>Eventos</summary><ol><li><a href="/es/docs/Web/Events/statechange"><code>statechange</code></a></li><li><a href="/es/docs/Web/Events/complete"><code>complete</code></a></li><li><a href="/es/docs/Web/Events/ended"><code>ended</code></a></li><li><a href="/es/docs/Web/Events/message"><code>message</code></a></li><li><a href="/es/docs/Web/Events/loaded"><code>loaded</code></a></li><li><a href="/es/docs/Web/Events/audioprocess"><code>audioprocess</code></a></li><li><a href="/es/docs/Web/Events/nodecreate"><code>nodecreate</code></a></li></ol></details></li><li class="toggle"><details open><summary>Páginas relacionadas a Web Audio API</summary><ol><li><a href="/es/docs/Web/API/AnalyserNode"><code>AnalyserNode</code></a></li><li><a href="/es/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a></li><li><a href="/es/docs/Web/API/AudioBufferSourceNode"><code>AudioBufferSourceNode</code></a></li><li><a href="/es/docs/Web/API/AudioContext"><code>AudioContext</code></a></li><li><a href="/es/docs/Web/API/AudioContextOptions"><code>AudioContextOptions</code></a></li><li><a href="/es/docs/Web/API/AudioDestinationNode"><code>AudioDestinationNode</code></a></li><li><a href="/es/docs/Web/API/AudioListener"><code>AudioListener</code></a></li><li><a href="/es/docs/Web/API/AudioNode"><code>AudioNode</code></a></li><li><a href="/es/docs/Web/API/AudioNodeOptions"><code>AudioNodeOptions</code></a></li><li><a href="/es/docs/Web/API/AudioParam"><code>AudioParam</code></a></li><li><a href="/es/docs/Web/API/AudioProcessingEvent"><code>AudioProcessingEvent</code></a></li><li><a href="/es/docs/Web/API/AudioScheduledSourceNode"><code>AudioScheduledSourceNode</code></a></li><li><a href="/es/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a></li><li><a href="/es/docs/Web/API/BiquadFilterNode"><code>BiquadFilterNode</code></a></li><li><a href="/es/docs/Web/API/ChannelMergerNode"><code>ChannelMergerNode</code></a></li><li><a href="/es/docs/Web/API/ChannelSplitterNode"><code>ChannelSplitterNode</code></a></li><li><a href="/es/docs/Web/API/ConstantSourceNode"><code>ConstantSourceNode</code></a></li><li><a href="/es/docs/Web/API/ConvolverNode"><code>ConvolverNode</code></a></li><li><a href="/es/docs/Web/API/DelayNode"><code>DelayNode</code></a></li><li><a href="/es/docs/Web/API/DynamicsCompressorNode"><code>DynamicsCompressorNode</code></a></li><li><a href="/es/docs/Web/API/GainNode"><code>GainNode</code></a></li><li><a href="/es/docs/Web/API/IIRFilterNode"><code>IIRFilterNode</code></a></li><li><a href="/es/docs/Web/API/MediaElementAudioSourceNode"><code>MediaElementAudioSourceNode</code></a></li><li><a href="/es/docs/Web/API/MediaStreamAudioDestinationNode"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href="/es/docs/Web/API/OfflineAudioCompletionEvent"><code>OfflineAudioCompletionEvent</code></a></li><li><a href="/es/docs/Web/API/OfflineAudioContext"><code>OfflineAudioContext</code></a></li><li><a href="/es/docs/Web/API/OscillatorNode"><code>OscillatorNode</code></a></li><li><a href="/es/docs/Web/API/PannerNode"><code>PannerNode</code></a></li><li><a href="/es/docs/Web/API/PeriodicWave"><code>PeriodicWave</code></a></li><li><a href="/es/docs/Web/API/StereoPannerNode"><code>StereoPannerNode</code></a></li><li><a href="/es/docs/Web/API/WaveShaperNode"><code>WaveShaperNode</code></a></li></ol></details></li></ol></section><p></p>

<div>
<p>La interfaz <code>MediaStreamAudioSourceNode</code> representa una fuente de audio compuesta por un <a href="/en-US/docs/WebRTC" title="/en-US/docs/WebRTC">WebRTC</a> <a href="/es/docs/Web/API/MediaStream" title="La documentación acerca de este tema no ha sido escrita todavía . ¡Por favor  considera contribuir !"><code>MediaStream</code></a> (tal como una cámara web o un micrófono.) Es un <a href="/es/docs/Web/API/AudioNode" title="La interfaz AudioNode es una interfaz genérica para representar un módulo de procesamiento de audio. Ejemplos:"><code>AudioNode</code></a> que actúa como una fuente de audio.</p>
</div>

<p>El <code>MediaElementSourceNode</code> no tiene entradas y una y sólo una salida, y es creado usando el método <a href="/es/docs/Web/API/AudioContext/createMediaStreamSource" title="La documentación acerca de este tema no ha sido escrita todavía . ¡Por favor  considera contribuir !"><code>AudioContext.createMediaStreamSource</code></a>.</p>

<p>La cantidad de canales en la salida es igual al número de canales en  <a href="/es/docs/Web/API/AudioMediaStreamTrack" title="La documentación acerca de este tema no ha sido escrita todavía . ¡Por favor  considera contribuir !"><code>AudioMediaStreamTrack</code></a>. Si no existe un flujo de media válido, entonces el número de canales de salida será un canal silencioso.</p>

<div class="note notecard">
<p><strong>Nota:</strong> <code>MediaStreamAudioSourceNode</code> selecciona la pista de audio automáticamente, y puede que no siempre sea predecible. Usted debería considerar seriamente usar el <a href="/es/docs/Web/API/MediaStreamTrackAudioSourceNode" title="La documentación acerca de este tema no ha sido escrita todavía . ¡Por favor  considera contribuir !"><code>MediaStreamTrackAudioSourceNode</code></a> en su lugar, que se crea especificando la pista exacta que desea utilizar.</p>
</div>

<table class="properties">
 <tbody>
  <tr>
   <th scope="row">Número de entradas</th>
   <td><code>0</code></td>
  </tr>
  <tr>
   <th scope="row">Número de salidas</th>
   <td><code>1</code></td>
  </tr>
  <tr>
   <th scope="row">Cantidad de canales</th>
   <td>definido por <a href="/es/docs/Web/API/AudioMediaStreamTrack"><code>AudioMediaStreamTrack</code></a> pasado al método  <a href="/es/docs/Web/API/AudioContext/createMediaStreamSource"><code>AudioContext.createMediaStreamSource</code></a> que lo creó.</td>
  </tr>
 </tbody>
</table>

<h2 id="Propiedades">Propiedades</h2>

<p><em>Heredadas de su padre, </em><em><a href="/es/docs/Web/API/AudioNode" title="La interfaz AudioNode es una interfaz genérica para representar un módulo de procesamiento de audio. Ejemplos:"><code>AudioNode</code></a></em>.</p>

<h2 id="Métodos">Métodos</h2>

<p><em>Heredadas de su padre, <a href="/es/docs/Web/API/AudioNode" title="La interfaz AudioNode es una interfaz genérica para representar un módulo de procesamiento de audio. Ejemplos:"><code>AudioNode</code></a></em>.</p>

<h2 id="Ejemplo">Ejemplo</h2>

<p></p><p>In this example, we grab a media (audio + video) stream from <a href="/en-US/docs/Web/API/Navigator/getUserMedia" title="The deprecated Navigator.getUserMedia() method prompts the user for permission to use up to one video input device (such as a camera or shared screen) and up to one audio input device (such as a microphone) as the source for a MediaStream."><code>navigator.getUserMedia</code></a>, feed the media into a <a href="/en-US/docs/Web/HTML/Element/video" title="The HTML Video element (&lt;video&gt;) embeds a media player which supports video playback into the document."><code>&lt;video&gt;</code></a> element to play then mute the audio, but then also feed the audio into a <a href="/en-US/docs/Web/API/MediaStreamAudioSourceNode" title="The MediaStreamAudioSourceNode interface is a type of AudioNode which operates as an audio source whose media is received from a MediaStream obtained using the WebRTC or Media Capture and Streams APIs."><code>MediaStreamAudioSourceNode</code></a>. Next, we feed this source audio into a low pass <a href="/en-US/docs/Web/API/BiquadFilterNode" title="The BiquadFilterNode interface represents a simple low-order filter, and is created using the AudioContext.createBiquadFilter() method. It is an AudioNode that can represent different kinds of filters, tone control devices, and graphic equalizers."><code>BiquadFilterNode</code></a> (which effectively serves as a bass booster), then a <a href="/en-US/docs/Web/API/AudioDestinationNode" title="AudioDestinationNode has no output (as it is the output, no more AudioNode can be linked after it in the audio graph) and one input. The number of channels in the input must be between 0 and the maxChannelCount value or an exception is raised."><code>AudioDestinationNode</code></a>.</p>

<p>The range slider below the <a href="/en-US/docs/Web/HTML/Element/video" title="The HTML Video element (&lt;video&gt;) embeds a media player which supports video playback into the document."><code>&lt;video&gt;</code></a> element controls the amount of gain given to the lowpass filter — increase the value of the slider to make the audio sound more bass heavy!</p>

<div class="note notecard">
<p><strong>Note</strong>: You can see this <a href="https://mdn.github.io/webaudio-examples/stream-source-buffer/">example running live</a>, or <a href="https://github.com/mdn/webaudio-examples/tree/master/stream-source-buffer">view the source</a>.</p>
</div>

<pre class="brush: js;highlight[23]">var pre = document.querySelector(&apos;pre&apos;);
var video = document.querySelector(&apos;video&apos;);
var myScript = document.querySelector(&apos;script&apos;);
var range = document.querySelector(&apos;input&apos;);

// getUserMedia block - grab stream
// put it into a MediaStreamAudioSourceNode
// also output the visuals into a video element

if (navigator.mediaDevices) {
    console.log(&apos;getUserMedia supported.&apos;);
    navigator.mediaDevices.getUserMedia ({audio: true, video: true})
    .then(function(stream) {
        video.srcObject = stream;
        video.onloadedmetadata = function(e) {
            video.play();
            video.muted = true;
        };

        // Create a MediaStreamAudioSourceNode
        // Feed the HTMLMediaElement into it
        var audioCtx = new AudioContext();
        var source = audioCtx.createMediaStreamSource(stream);

        // Create a biquadfilter
        var biquadFilter = audioCtx.createBiquadFilter();
        biquadFilter.type = &quot;lowshelf&quot;;
        biquadFilter.frequency.value = 1000;
        biquadFilter.gain.value = range.value;

        // connect the AudioBufferSourceNode to the gainNode
        // and the gainNode to the destination, so we can play the
        // music and adjust the volume using the mouse cursor
        source.connect(biquadFilter);
        biquadFilter.connect(audioCtx.destination);

        // Get new mouse pointer coordinates when mouse is moved
        // then set new gain value

        range.oninput = function() {
            biquadFilter.gain.value = range.value;
        }
    })
    .catch(function(err) {
        console.log(&apos;The following gUM error occured: &apos; + err);
    });
} else {
   console.log(&apos;getUserMedia not supported on your browser!&apos;);
}

// dump script to pre element

pre.innerHTML = myScript.innerHTML;</pre>

<div class="note notecard">
<p><strong>Note</strong>: As a consequence of calling <code>createMediaStreamSource()</code>, audio playback from the media stream will be re-routed into the processing graph of the <a href="/en-US/docs/Web/API/AudioContext" title="The AudioContext interface represents an audio-processing graph built from audio modules linked together, each represented by an AudioNode."><code>AudioContext</code></a>. So playing/pausing the stream can still be done through the media element API and the player controls.</p>
</div><p></p>

<h2 id="Especificación">Especificación</h2>

<table class="standard-table">
 <tbody>
  <tr>
   <th scope="col">Especificación</th>
   <th scope="col">Estado</th>
   <th scope="col">Comentario</th>
  </tr>
  <tr>
   <td><a lang="en" href="https://webaudio.github.io/web-audio-api/#the-mediastreamaudiosourcenode-interface" class="external" hreflang="en">Web Audio API<br><small lang="es">La definición de &apos;MediaStreamAudioSourceNode&apos; en esta especificación.</small></a></td>
   <td><span class="spec-WD">Working Draft</span></td>
   <td> </td>
  </tr>
 </tbody>
</table>

<h2 id="Compatibilidad_con_navegadores">Compatibilidad con navegadores</h2>

<div><div class="warning notecard"><strong><a href="https://github.com/mdn/browser-compat-data">We&apos;re converting our compatibility data into a machine-readable JSON format</a></strong>.
            This compatibility table still uses the old format,
            because we haven&apos;t yet converted the data it contains.
            <strong><a href="/es/docs/MDN/Contribute/Structures/Compatibility_tables">Find out how you can help!</a></strong></div>

<div class="htab">
    <a id="AutoCompatibilityTable" name="AutoCompatibilityTable"></a>
    <ul>
        <li class="selected"><a>Escritorio</a></li>
        <li><a>Móvil</a></li>
    </ul>
</div></div>

<div id="compat-desktop">
<table class="compat-table">
 <tbody>
  <tr>
   <th>Caracterísitica</th>
   <th>Chrome</th>
   <th>Firefox (Gecko)</th>
   <th>Internet Explorer</th>
   <th>Opera</th>
   <th>Safari (WebKit)</th>
  </tr>
  <tr>
   <td>Soporte básico</td>
   <td>14 <span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/es/docs/Web/Guide/Prefixes">webkit</a></span></td>
   <td><a href="/en-US/Firefox/Releases/25">25</a> (25)</td>
   <td><span style="color: #f00;">Sin soporte</span></td>
   <td>15 <span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/es/docs/Web/Guide/Prefixes">webkit</a></span><br>
    22 (unprefixed)</td>
   <td>6 <span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/es/docs/Web/Guide/Prefixes">webkit</a></span></td>
  </tr>
 </tbody>
</table>
</div>

<div id="compat-mobile">
<table class="compat-table">
 <tbody>
  <tr>
   <th>Caracterísitica</th>
   <th>Android</th>
   <th>Chrome</th>
   <th>Firefox Mobile (Gecko)</th>
   <th>Firefox OS</th>
   <th>IE Phone</th>
   <th>Opera Mobile</th>
   <th>Safari Mobile</th>
  </tr>
  <tr>
   <td>Soporte básico</td>
   <td><span style="color: #f00;">Sin soporte</span></td>
   <td>28 <span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/es/docs/Web/Guide/Prefixes">webkit</a></span></td>
   <td>25.0 (25)</td>
   <td>1.2</td>
   <td><span style="color: #f00;">Sin soporte</span></td>
   <td><span style="color: #f00;">Sin soporte</span></td>
   <td>6 <span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/es/docs/Web/Guide/Prefixes">webkit</a></span></td>
  </tr>
 </tbody>
</table>
</div>

<h2 id="Ver_también">Ver también</h2>

<ul>
 <li><a href="/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li>
</ul>
