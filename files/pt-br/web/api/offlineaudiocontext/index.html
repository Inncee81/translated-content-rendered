---
title: OfflineAudioContext
slug: Web/API/OfflineAudioContext
translation_of: Web/API/OfflineAudioContext
---
<div><section class="Quick_links" id="Quick_Links"><ol><li><strong><a href="/pt-BR/docs/Web/API/Web_Audio_API">Web Audio API</a></strong></li><li><strong><a href="/pt-BR/docs/Web/API/OfflineAudioContext"><code>OfflineAudioContext</code></a></strong></li><li class="toggle"><details open><summary>Construtor</summary><ol><li><a href="/pt-BR/docs/Web/API/OfflineAudioContext/OfflineAudioContext"><code>OfflineAudioContext()</code></a> <a href="/pt-BR/docs/Web/API/OfflineAudioContext/OfflineAudioContext$translate" style="opacity: 0.5;">[Traduzir]</a></li></ol></details></li><li class="toggle"><details open><summary>Propriedades</summary><ol><li><a href="/pt-BR/docs/Web/API/OfflineAudioContext/length"><code>length</code></a> <a href="/pt-BR/docs/Web/API/OfflineAudioContext/length$translate" style="opacity: 0.5;">[Traduzir]</a></li><li><a href="/pt-BR/docs/Web/API/OfflineAudioContext/oncomplete"><code>oncomplete</code></a> <a href="/pt-BR/docs/Web/API/OfflineAudioContext/oncomplete$translate" style="opacity: 0.5;">[Traduzir]</a></li></ol></details></li><li class="toggle"><details open><summary>Métodos</summary><ol><li><a href="/pt-BR/docs/Web/API/OfflineAudioContext/resume"><code>resume()</code></a> <a href="/pt-BR/docs/Web/API/OfflineAudioContext/resume$translate" style="opacity: 0.5;">[Traduzir]</a></li><li><a href="/pt-BR/docs/Web/API/OfflineAudioContext/startRendering"><code>startRendering()</code></a> <a href="/pt-BR/docs/Web/API/OfflineAudioContext/startRendering$translate" style="opacity: 0.5;">[Traduzir]</a></li><li><a href="/pt-BR/docs/Web/API/OfflineAudioContext/suspend"><code>suspend()</code></a> <a href="/pt-BR/docs/Web/API/OfflineAudioContext/suspend$translate" style="opacity: 0.5;">[Traduzir]</a></li></ol></details></li><li class="toggle"><details open><summary>Eventos</summary><ol><li><a href="/pt-BR/docs/Web/API/OfflineAudioContext/complete_event"><code>complete</code></a> <a href="/pt-BR/docs/Web/API/OfflineAudioContext/complete_event$translate" style="opacity: 0.5;">[Traduzir]</a></li></ol></details></li><li class="toggle"><details open><summary>Herança:</summary><ol><li><a href="/pt-BR/docs/Web/API/AudioContext"><code>AudioContext</code></a></li><li><a href="/pt-BR/docs/Web/API/EventTarget"><code>EventTarget</code></a></li></ol></details></li><li class="toggle"><details open><summary>Páginas relacionadas a Web Audio API</summary><ol><li><a href="/pt-BR/docs/Web/API/AnalyserNode"><code>AnalyserNode</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioBufferSourceNode"><code>AudioBufferSourceNode</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioContext"><code>AudioContext</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioContextOptions"><code>AudioContextOptions</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioDestinationNode"><code>AudioDestinationNode</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioListener"><code>AudioListener</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioNode"><code>AudioNode</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioNodeOptions"><code>AudioNodeOptions</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioParam"><code>AudioParam</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioProcessingEvent"><code>AudioProcessingEvent</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioScheduledSourceNode"><code>AudioScheduledSourceNode</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioWorklet"><code>AudioWorklet</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioWorkletGlobalScope"><code>AudioWorkletGlobalScope</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioWorkletNode"><code>AudioWorkletNode</code></a></li><li><a href="/pt-BR/docs/Web/API/AudioWorkletProcessor"><code>AudioWorkletProcessor</code></a></li><li><a href="/pt-BR/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a></li><li><a href="/pt-BR/docs/Web/API/BiquadFilterNode"><code>BiquadFilterNode</code></a></li><li><a href="/pt-BR/docs/Web/API/ChannelMergerNode"><code>ChannelMergerNode</code></a></li><li><a href="/pt-BR/docs/Web/API/ChannelSplitterNode"><code>ChannelSplitterNode</code></a></li><li><a href="/pt-BR/docs/Web/API/ConstantSourceNode"><code>ConstantSourceNode</code></a></li><li><a href="/pt-BR/docs/Web/API/ConvolverNode"><code>ConvolverNode</code></a></li><li><a href="/pt-BR/docs/Web/API/DelayNode"><code>DelayNode</code></a></li><li><a href="/pt-BR/docs/Web/API/DynamicsCompressorNode"><code>DynamicsCompressorNode</code></a></li><li><a href="/pt-BR/docs/Web/API/GainNode"><code>GainNode</code></a></li><li><a href="/pt-BR/docs/Web/API/IIRFilterNode"><code>IIRFilterNode</code></a></li><li><a href="/pt-BR/docs/Web/API/MediaElementAudioSourceNode"><code>MediaElementAudioSourceNode</code></a></li><li><a href="/pt-BR/docs/Web/API/MediaStreamAudioDestinationNode"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href="/pt-BR/docs/Web/API/MediaStreamAudioSourceNode"><code>MediaStreamAudioSourceNode</code></a></li><li><a href="/pt-BR/docs/Web/API/OfflineAudioCompletionEvent"><code>OfflineAudioCompletionEvent</code></a></li><li><a href="/pt-BR/docs/Web/API/OscillatorNode"><code>OscillatorNode</code></a></li><li><a href="/pt-BR/docs/Web/API/PannerNode"><code>PannerNode</code></a></li><li><a href="/pt-BR/docs/Web/API/PeriodicWave"><code>PeriodicWave</code></a></li><li><a href="/pt-BR/docs/Web/API/StereoPannerNode"><code>StereoPannerNode</code></a></li><li><a href="/pt-BR/docs/Web/API/WaveShaperNode"><code>WaveShaperNode</code></a></li></ol></details></li></ol></section></div>

<div>A interface <code>OfflineAudioContext</code> é uma interface <a href="/pt-BR/docs/Web/API/AudioContext"><code>AudioContext</code></a> que representa um gráfico de processament de áudio construido a partir de conexões entre <a href="/pt-BR/docs/Web/API/AudioNode"><code>AudioNode</code></a>s. Em contraste com o padrão <a href="/pt-BR/docs/Web/API/AudioContext"><code>AudioContext</code></a>, um <code>OfflineAudioContext</code> não processa o áudio para o hardware do dispositivo; Em vez disso, ele gera, o mais rápido possível, e exibe o resultado para um <a href="/pt-BR/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a>.</div>

<div class="hidden" id="inheritance_diagram">

<pre class="brush: html notranslate">  &lt;div id=&quot;interfaceDiagram&quot; style=&quot;display: inline-block; position: relative; width: 100%; padding-bottom: 11.666666666666666%; vertical-align: middle; overflow: hidden;&quot;&gt;&lt;svg style=&quot;display: inline-block; position: absolute; top: 0; left: 0;&quot; viewbox=&quot;-50 0 600 70&quot; preserveAspectRatio=&quot;xMinYMin meet&quot;&gt;&lt;a xlink:href=&quot;https://developer.mozilla.org/pt-BR/docs/Web/API/EventTarget&quot; target=&quot;_top&quot;&gt;&lt;rect x=&quot;1&quot; y=&quot;1&quot; width=&quot;110&quot; height=&quot;50&quot; fill=&quot;#fff&quot; stroke=&quot;#D4DDE4&quot; stroke-width=&quot;2px&quot; /&gt;&lt;text  x=&quot;56&quot; y=&quot;30&quot; font-size=&quot;12px&quot; font-family=&quot;Consolas,Monaco,Andale Mono,monospace&quot; fill=&quot;#4D4E53&quot; text-anchor=&quot;middle&quot; alignment-baseline=&quot;middle&quot;&gt;EventTarget&lt;/text&gt;&lt;/a&gt;&lt;polyline points=&quot;111,25  121,20  121,30  111,25&quot; stroke=&quot;#D4DDE4&quot; fill=&quot;none&quot;/&gt;&lt;line x1=&quot;121&quot; y1=&quot;25&quot; x2=&quot;151&quot; y2=&quot;25&quot; stroke=&quot;#D4DDE4&quot;/&gt;&lt;a xlink:href=&quot;https://developer.mozilla.org/pt-BR/docs/Web/API/AudioContext&quot; target=&quot;_top&quot;&gt;&lt;rect x=&quot;151&quot; y=&quot;1&quot; width=&quot;120&quot; height=&quot;50&quot; fill=&quot;#fff&quot; stroke=&quot;#D4DDE4&quot; stroke-width=&quot;2px&quot; /&gt;&lt;text  x=&quot;211&quot; y=&quot;30&quot; font-size=&quot;12px&quot; font-family=&quot;Consolas,Monaco,Andale Mono,monospace&quot; fill=&quot;#4D4E53&quot; text-anchor=&quot;middle&quot; alignment-baseline=&quot;middle&quot;&gt;AudioContext&lt;/text&gt;&lt;/a&gt;&lt;polyline points=&quot;271,25  281,20  281,30  271,25&quot; stroke=&quot;#D4DDE4&quot; fill=&quot;none&quot;/&gt;&lt;line x1=&quot;281&quot; y1=&quot;25&quot; x2=&quot;311&quot; y2=&quot;25&quot; stroke=&quot;#D4DDE4&quot;/&gt;&lt;a xlink:href=&quot;https://developer.mozilla.org/pt-BR/docs/Web/API/OfflineAudioContext&quot; target=&quot;_top&quot;&gt;&lt;rect x=&quot;311&quot; y=&quot;1&quot; width=&quot;190&quot; height=&quot;50&quot; fill=&quot;#F4F7F8&quot; stroke=&quot;#D4DDE4&quot; stroke-width=&quot;2px&quot; /&gt;&lt;text  x=&quot;406&quot; y=&quot;30&quot; font-size=&quot;12px&quot; font-family=&quot;Consolas,Monaco,Andale Mono,monospace&quot; fill=&quot;#4D4E53&quot; text-anchor=&quot;middle&quot; alignment-baseline=&quot;middle&quot;&gt;OfflineAudioContext&lt;/text&gt;&lt;/a&gt;&lt;/svg&gt;&lt;/div&gt;
</pre>

<pre class="brush: css notranslate">  a:hover text { fill: #0095DD; pointer-events: all;}
</pre>

</div>

<iframe class="live-sample-frame inheritance-diagram-frame" frameborder="0" height="70" id="frame_inheritance_diagram" src="https://mdn.mozillademos.org/pt-BR/docs/Web/API/OfflineAudioContext$samples/inheritance_diagram?revision=1482608" width="600"></iframe>

<h2 id="Construtor">Construtor</h2>

<dl>
 <dt><a href="/pt-BR/docs/Web/API/OfflineAudioContext/OfflineAudioContext"><code>OfflineAudioContext.OfflineAudioContext()</code></a></dt>
 <dd>Cria uma nova instância <code>OfflineAudioContext</code>.</dd>
</dl>

<h2 id="Propriedades">Propriedades</h2>

<p><em>Também herda propriedades da sua entidade paterna, <a href="/pt-BR/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a>.</em></p>

<dl>
 <dt><a href="/pt-BR/docs/Web/API/OfflineAudioContext/length"><code>OfflineAudioContext.length</code></a> <span class="readOnly readOnlyInline notecard inline" title="Este valor não pode ser alterado.">Somente leitura </span></dt>
 <dd>
 <p>Um número inteiro que representa o tamanho do buffer em quadros de amostra.</p>
 </dd>
</dl>

<h3 id="Manipuladores_de_Eventos">Manipuladores de Eventos</h3>

<dl>
 <dt><a href="/pt-BR/docs/Web/API/OfflineAudioContext/oncomplete"><code>OfflineAudioContext.oncomplete</code></a></dt>
 <dd>É uma chamada <a href="/pt-BR/docs/Web/API/EventHandler"><code>EventHandler</code></a> quando o processamento é encerrado, é quando o evento <code><a href="/pt-BR/docs/Web/Reference/Events/complete" title="/pt-BR/docs/Web/Reference/Events/complete">complete</a></code>  - do tipo <a href="/pt-BR/docs/Web/API/OfflineAudioCompletionEvent"><code>OfflineAudioCompletionEvent</code></a> - é gerado, após a versão baseada em eventos do <a href="/pt-BR/docs/Web/API/OfflineAudioContext/startRendering"><code>OfflineAudioContext.startRendering()</code></a> é usada.</dd>
</dl>

<h2 id="Métodos">Métodos</h2>

<p><em>Também herda métodos da interface paterna, <a href="/pt-BR/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a>.</em></p>

<dl>
 <dt><a href="/pt-BR/docs/Web/API/OfflineAudioContext/resume"><code>OfflineAudioContext.resume()</code></a></dt>
 <dd>
 <p>Programa uma suspensão da progressão do tempo no contexto de áudio no horário especificado e retorna uma promessa.</p>
 </dd>
 <dt><a href="/pt-BR/docs/Web/API/OfflineAudioContext/suspend"><code>OfflineAudioContext.suspend()</code></a></dt>
 <dd>
 <p>Agende uma suspensão da progressão do tempo no contexto de áudio no horário especificado e retorna uma promessa.</p>
 </dd>
 <dt><a href="/pt-BR/docs/Web/API/OfflineAudioContext/startRendering"><code>OfflineAudioContext.startRendering()</code></a></dt>
 <dd>
 <p>Inicia a renderização do áudio, levando em consideração as conexões atuais e as mudanças programadas atuais. Esta página abrange a versão baseada em eventos e a versão baseada em promessas.</p>
 </dd>
</dl>

<h2 id="Exemplo">Exemplo</h2>

<p>Nesse exemplo, declaramos um ambos <a href="/pt-BR/docs/Web/API/AudioContext"><code>AudioContext</code></a> e um <code>OfflineAudioContext</code> objeto. Nós usamos o <code>AudioContext</code> para carregar uma faixa de áudio via XHR (<a href="/pt-BR/docs/Web/API/AudioContext/decodeAudioData"><code>AudioContext.decodeAudioData</code></a>), então o <code>OfflineAudioContext</code> para renderizar o áudio em um <a href="/pt-BR/docs/Web/API/AudioBufferSourceNode"><code>AudioBufferSourceNode</code></a> e reproduzir a trilha. Depois que o gráfico de áudio off-line estiver configurado, você deve renderizá-lo para <a href="/pt-BR/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a> usando <a href="/pt-BR/docs/Web/API/OfflineAudioContext/startRendering"><code>OfflineAudioContext.startRendering</code></a>.</p>

<p>Quando a &apos;promise&apos; <code>startRendering()</code> é resolvida, a renderização foi concluída e a saída <code>AudioBuffer</code> é retornada fora da &apos;promise.</p>

<p>Neste ponto, criamos outro contexto de áudio, criamos um <a href="/pt-BR/docs/Web/API/AudioBufferSourceNode"><code>AudioBufferSourceNode</code></a> dentro dele e configuramos o buffer para ser igual à promessa <code>AudioBuffer</code>. Isso é jogado como parte de um gráfico de áudio padrão simples.</p>

<div class="note notecard">
<p><strong>Nota</strong>: Para um exemplo de trabalho, veja nosso <a href="https://mdn.github.io/webaudio-examples/offline-audio-context-promise/">offline-audio-context-promise</a> Github repo (veja o <a href="https://github.com/mdn/webaudio-examples/tree/master/offline-audio-context-promise">código fonte</a> também.)</p>
</div>

<pre class="brush: js notranslate">// define o contexto de áudio online e offline

var audioCtx = new AudioContext();
var offlineCtx = new OfflineAudioContext(2,44100*40,44100);

source = offlineCtx.createBufferSource();

// usa XHR para carregar uma faixa de áudio, e
// decodeAudioData para decodificar e OfflineAudioContext para renderizar

function getData() {
  request = new XMLHttpRequest();

  request.open(&apos;GET&apos;, &apos;viper.ogg&apos;, true);

  request.responseType = &apos;arraybuffer&apos;;

  request.onload = function() {
    var audioData = request.response;

    audioCtx.decodeAudioData(audioData, function(buffer) {
      myBuffer = buffer;
      source.buffer = myBuffer;
      source.connect(offlineCtx.destination);
      source.start();
      //source.loop = true;
      offlineCtx.startRendering().then(function(renderedBuffer) {
        console.log(&apos;Rendering completed successfully&apos;);
        var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        var song = audioCtx.createBufferSource();
        song.buffer = renderedBuffer;

        song.connect(audioCtx.destination);

        play.onclick = function() {
          song.start();
        }
      }).catch(function(err) {
          console.log(&apos;Rendering failed: &apos; + err);
          // Nota: A promessa deve rejeitar quando o StartRendering é chamado uma segunda vez em um OfflineAudioContext
      });
    });
  }

  request.send();
}

// Run getData to start the process off

getData();</pre>

<h2 id="Especificações">Especificações</h2>

<table class="standard-table">
 <tbody>
  <tr>
   <th scope="col">Specification</th>
   <th scope="col">Status</th>
   <th scope="col">Comment</th>
  </tr>
  <tr>
   <td><a class="external" href="https://webaudio.github.io/web-audio-api/#OfflineAudioContext" hreflang="en" lang="en">Web Audio API<br><small lang="pt-BR">The definition of &apos;OfflineAudioContext&apos; in that specification.</small></a></td>
   <td><span class="spec-WD">Rascunho atual</span></td>
   <td>Initial definition</td>
  </tr>
 </tbody>
</table>

<h2 id="Compatibilidade_de_NavegadoresBrowser">Compatibilidade de Navegadores/Browser</h2>

<div>
<div class="hidden">
<p>A tabela de compatibilidade nesta página é gerada a partir de dados estruturados. Se você quiser contribuir com os dados, verifique <a href="https://github.com/mdn/browser-compat-data">https://github.com/mdn/browser-compat-data</a> e envie-nos um pedido de &apos;pull&apos;.</p>
</div>

<div class="bc-data" id="bcd:api.OfflineAudioContext"></div>
</div>

<h2 id="Veja_também">Veja também</h2>

<ul>
 <li><a href="/en-US/docs/Web_Audio_API/Using_Web_Audio_API">Usando a API de áudio da Web</a></li>
</ul>
