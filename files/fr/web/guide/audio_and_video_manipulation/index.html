---
title: Manipulation Audio et Vidéo
slug: Web/Guide/Audio_and_video_manipulation
tags:
  - Audio
  - Canvas
  - HTML5
  - Video
  - Web Audio API
  - WebGL
translation_of: Web/Guide/Audio_and_video_manipulation
---
<div class="summary">
<p>La beauté du web est qu'on peut combiner différentes technologies pour en créer de nouvelles. Avoir de l'audio et vidéo nativement dans le navigateur nous donne la possibilité d'utiliser ces flux de données avec d'autres technologies comme <a href="/fr/docs/Web/HTML/Element/canvas" title="L'élément &lt;canvas> permet de modifier une zone graphique via un script (habituellement en JavaScript ou grâce à WebGL). Il peut par exemple être utilisé afin de dessiner des graphiques, manipuler des images ou jouer des animations."><code>&lt;canvas&gt;</code></a>, <a href="/fr/docs/Web/API/WebGL_API">WebGL</a> ou <a href="/fr/docs/Web/API/Web_Audio_API">Web Audio API</a> pour modifier le média — par exemple ajouter des effets de réverbération ou de compression à l'audio, ou encore des filtres noir &amp; blanc/sépia aux vidéos. Cet article fournit une référence pour expliquer ce que vous pouvez faire.</p>
</div>

<h2 id="Manipulation_Vidéo">Manipulation Vidéo</h2>

<p>La possibilité de lire les valeurs de pixels de chaque image d'une vidéo peut être très utile, cela nous permet de placer ces images dans d'autres contextes.</p>

<h3 id="Vidéo_et_Canvas">Vidéo et Canvas</h3>

<p><a href="/fr/docs/Web/HTML/Element/canvas" title="L'élément &lt;canvas> permet de modifier une zone graphique via un script (habituellement en JavaScript ou grâce à WebGL). Il peut par exemple être utilisé afin de dessiner des graphiques, manipuler des images ou jouer des animations."><code>&lt;canvas&gt;</code></a> est un moyen de dessiner de manière scripté sur des pages web; c'est un outil très puissant et qui peut être couplé avec du contenu vidéo.</p>

<p>La technique générale est comme suit:</p>

<ol>
 <li>Dessiner une image de l'élément <a href="/fr/docs/Web/HTML/Element/video" title="L'élément HTML &lt;video> intègre un contenu vidéo dans un document."><code>&lt;video&gt;</code></a> sur un élément <a href="/fr/docs/Web/HTML/Element/canvas" title="L'élément &lt;canvas> permet de modifier une zone graphique via un script (habituellement en JavaScript ou grâce à WebGL). Il peut par exemple être utilisé afin de dessiner des graphiques, manipuler des images ou jouer des animations."><code>&lt;canvas&gt;</code></a> intermédiaire.</li>
 <li>Lire les données de l'élément <code>&lt;canvas&gt;</code> et les manipuler.</li>
 <li>Écrire les données manipulées dans le <code>&lt;canvas&gt;</code> que l'on veut afficher.</li>
 <li>Marquer une pause et répéter.</li>
</ol>

<p>On peut configurer notre lecteur vidéo et l'élément <code>&lt;canvas&gt;</code> comme ceci:</p>

<pre class="brush: html">&lt;video id="my-video" controls="true" width="480" height="270" crossorigin="anonymous"&gt;
  &lt;source src="http://jplayer.org/video/webm/Big_Buck_Bunny_Trailer.webm" type="video/webm"&gt;
  &lt;source src="http://jplayer.org/video/m4v/Big_Buck_Bunny_Trailer.m4v" type="video/mp4"&gt;
&lt;/video&gt;

&lt;canvas id="my-canvas" width="480" height="270"&gt;&lt;/canvas&gt;</pre>

<p>Et les manipuler comme ceci: (en l'occurence, on affiche une version en noir et blanc de la vidéo)</p>

<pre class="brush: js">var processor = {
  timerCallback: function() {
    if (this.video.paused || this.video.ended) {
      return;
    }
    this.computeFrame();
    var self = this;
    setTimeout(function () {
      self.timerCallback();
    }, 16); // roughly 60 frames per second
  },

  doLoad: function() {
    this.video = document.getElementById("my-video");
    this.c1 = document.getElementById("my-canvas");
    this.ctx1 = this.c1.getContext("2d");
    var self = this;

    this.video.addEventListener("play", function() {
      self.width = self.video.width;
      self.height = self.video.height;
      self.timerCallback();
    }, false);
  },

  computeFrame: function() {
    this.ctx1.drawImage(this.video, 0, 0, this.width, this.height);
    var frame = this.ctx1.getImageData(0, 0, this.width, this.height);
    var l = frame.data.length / 4;

    for (var i = 0; i &lt; l; i++) {
      var grey = (frame.data[i * 4 + 0] + frame.data[i * 4 + 1] + frame.data[i * 4 + 2]) / 3;

      frame.data[i * 4 + 0] = grey;
      frame.data[i * 4 + 1] = grey;
      frame.data[i * 4 + 2] = grey;
    }
    this.ctx1.putImageData(frame, 0, 0);

    return;
  }
};  </pre>

<p>Une fois que la page est chargée, on peut appeler</p>

<pre class="brush: js">processor.doLoad()</pre>

<p><iframe src="https://mdn.mozillademos.org/fr/docs/Web/Guide/Audio_and_video_manipulation$samples/Vid%C3%A9o_et_Canvas?revision=1460142" width="100%" height="550" frameborder="0" class="live-sample-frame sample-code-frame" id="frame_Vidéo_et_Canvas"></iframe></p>

<div class="note">
<p><strong>Note</strong>: En raison de problèmes de sécurité potentiels, si votre vidéo se trouve sur un domaine différent de votre page, vous devez activer <a href="/fr/docs/Web/HTTP/CORS">CORS (Cross Origin Resource Sharing)</a> sur le serveur qui héberge la vidéo et utiliser l'attribut <code>crossorigin</code> sur la balise vidéo.</p>
</div>

<div class="note">
<p><strong>Note</strong>: L'exemple présenté est un exemple minimal de manipulation vidéo avec canvas; pour plus d'efficacité, vous pouvez envisager d'utiliser requestAnimationFrame à la place de setTimeout pour les navigateurs qui le prennent en charge.</p>
</div>

<h3 id="Vidéo_e_WebGL">Vidéo e WebGL</h3>

<p><a href="/en-US/docs/Web/WebGL">WebGL</a> est une API puissante qui utilise canvas pour (typiquement) afficher des scènes en trois dimensions. On peut combiner WebGL et l'élément <a href="/fr/docs/Web/HTML/Element/video" title="L'élément HTML &lt;video> intègre un contenu vidéo dans un document."><code>&lt;video&gt;</code></a> pour créer des textures vidéo, ce qui veut dire que vous pouvez placer une vidéo dans des scènes 3D.</p>

<p>Exemple:</p>

<p><iframe src="https://mdn.github.io/webgl-examples/tutorial/sample8/index.html" width="670" class="live-sample-frame" height="510" frameborder="0"></iframe></p>

<div class="note">
<p><strong>Note</strong>: Vous pouvez trouver le <a href="https://github.com/mdn/webgl-examples/tree/gh-pages/tutorial/sample8">code source de cette démo sur GitHub</a> (<a href="https://mdn.github.io/webgl-examples/tutorial/sample8/">la voir en direct</a> aussi).</p>
</div>

<h3 id="Vitesse_de_lecture">Vitesse de lecture</h3>

<p>On peut ajuster la vitesse de lecture de l'audio et vidéo en utilisant l'attribut <code>playbackRate</code> (voir <a href="/fr/docs/Web/API/HTMLMediaElement" title="L'interface HTMLMediaElement ajoute à HTMLElement les propriétés et les méthodes nécessaires pour prendre en charge les fonctionnalités de base liées aux médias qui sont communes aux vidéos et aux documents audios. HTMLVideoElement et HTMLAudioElement héritent de cette interface."><code>HTMLMediaElement</code></a>). Il prend pour valeur un nombre qui est le coefficient à appliquer à la vitesse de lecture: par exemple, 0.5 représente la moitié de la vitesse tandis que 2 représente le double.<br>
 <br>
 HTML:</p>

<pre class="brush: html">&lt;video id="my-video" controls src="http://jplayer.org/video/m4v/Big_Buck_Bunny_Trailer.m4v"&gt;&lt;/video&gt;</pre>

<p>JavaScript:</p>

<pre class="brush: js">var myVideo = document.getElementById('my-video');
myVideo.playbackRate = 2;</pre>

<div class="hidden">
<h6 id="Playable_code" name="Playable_code">Playable code</h6>

<pre class="brush: html">&lt;video id="my-video" controls="true" width="480" height="270"&gt;
  &lt;source src="http://jplayer.org/video/webm/Big_Buck_Bunny_Trailer.webm" type="video/webm"&gt;
  &lt;source src="http://jplayer.org/video/m4v/Big_Buck_Bunny_Trailer.m4v" type="video/mp4"&gt;
&lt;/video&gt;
&lt;div class="playable-buttons"&gt;
  &lt;input id="edit" type="button" value="Edit" /&gt;
  &lt;input id="reset" type="button" value="Reset" /&gt;
&lt;/div&gt;
&lt;textarea id="code" class="playable-code"&gt;
var myVideo = document.getElementById('my-video');
myVideo.playbackRate = 2;&lt;/textarea&gt;
</pre>

<pre class="brush: js">var textarea = document.getElementById('code');
var reset = document.getElementById('reset');
var edit = document.getElementById('edit');
var code = textarea.value;

function setPlaybackRate() {
  eval(textarea.value);
}

reset.addEventListener('click', function() {
  textarea.value = code;
  setPlaybackRate();
});

edit.addEventListener('click', function() {
  textarea.focus();
})

textarea.addEventListener('input', setPlaybackRate);
window.addEventListener('load', setPlaybackRate);
</pre>
</div>

<p><iframe src="https://mdn.mozillademos.org/fr/docs/Web/Guide/Audio_and_video_manipulation$samples/Playable_code?revision=1460142" width="700" height="425" frameborder="0" class="live-sample-frame sample-code-frame" id="frame_Playable_code"></iframe></p>

<div class="note">
<p><strong>Note</strong>: Essayez l' <a href="http://jsbin.com/qomuvefu/2/edit">exemple playbackRate</a> en direct.</p>
</div>

<div class="note">
<p><strong>Note</strong> : <code>playbackRate</code> marche avec les éléments <code>&lt;audio&gt;</code> et <code><code>&lt;video&gt;</code></code>; cependant, dans les deux cas, la vitesse change mais pas la hauteur du son. Pour manipuler la hauteur du son, vous devez utliliser l'API Web Audio — voir la propriété <a href="/fr/docs/Web/API/AudioBufferSourceNode/playbackRate" title="Une valeur de 1.0 (c'est ) indique que le son doit être lu à la vitesse de son taux d'échantillonnage, une valeur inférieure qu'il doit être lu plus lentement, et une valeur supérieure plus rapidement. la valeur par défaut est 1.0. Pour toute autre valeur l'AudioBufferSourceNode rééchantillone le son avant de l'envoyer vers la sortie."><code>AudioBufferSourceNode.playbackRate</code></a>.</p>
</div>

<h2 id="Manipulation_Audio">Manipulation Audio</h2>

<p>Laissons <code>playbackRate</code> de côté. Pour manipuler l'audio, on utilise typiquement l'<a href="/en-US/docs/Web/API/Web_Audio_API">API Web Audio</a>.</p>

<h3 id="Sélectionner_une_source_audio">Sélectionner une source audio</h3>

<p>On peut utiliser la piste audio d'un élément <a href="/fr/docs/Web/HTML/Element/audio" title="L'élément HTML &lt;audio> est utilisé afin d'intégrer un contenu sonore dans un document. Il peut contenir une ou plusieurs sources audio représentées avec l'attribut src ou l'élément &lt;source>. S'il y a plusieurs sources, l'agent utilisateur choisira celle qui convient le mieux."><code>&lt;audio&gt;</code></a> ou <a href="/fr/docs/Web/HTML/Element/video" title="L'élément HTML &lt;video> intègre un contenu vidéo dans un document."><code>&lt;video&gt;</code></a> comme source pour alimenter l'API Web Audio, ou un simple buffer audio, une onde sinusoïdale/oscillateur, un flux (comme <a href="/fr/docs/NavigatorUserMedia.getUserMedia">getUserMedia</a> de <a href="/fr/docs/Web/API/WebRTC_API">WebRTC</a>)... Découvrez exactement comment les utiliser en lisant les pages suivantes:</p>

<ul>
 <li><a href="/fr/docs/Web/API/MediaElementAudioSourceNode" title="Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant !"><code>MediaElementAudioSourceNode</code></a></li>
 <li><a href="/fr/docs/Web/API/AudioBufferSourceNode" title="L'interface AudioBufferSourceNode est un AudioScheduledSourceNode qui représente une source audio constituée de données audio en mémoire, stockées dans un AudioBuffer. Elle est particulièrement utile pour lire des sons qui requierrent des conditions de lecture particulières, comme la synchronisation sur un certain rythme, et peuvent être stockés en mémoire. Si ce type de son doit être lu depuis le disque ou le réseau, il conviendra d'utiliser un AudioWorkletNode. "><code>AudioBufferSourceNode</code></a></li>
 <li><a href="/fr/docs/Web/API/OscillatorNode" title="On crée un OscillatorNode en utilisant la méthode AudioContext.createOscillator. Il a toujours exactement une sortie, et aucune entrée. Ses propriétés par défaut (voir AudioNode pour la définition) sont :"><code>OscillatorNode</code></a></li>
 <li><a href="/fr/docs/Web/API/MediaStreamAudioSourceNode" title="Un MediaElementSourceNode n'a pas d'entrée et une seule sortie. On le créé en utilisant la méthode AudioContext.createMediaStreamSource. Le nombre de canaux de sortie est égal au nombre de canaux de AudioMediaStreamTrack. S'il n'y a pas de media stream valide, alors la sortie sera constituée d'un seul canal silencieux."><code>MediaStreamAudioSourceNode</code></a></li>
</ul>

<h3 id="Filtres_Audio">Filtres Audio</h3>

<p>L'API Web Audio a beaucoup de différents filtres/effets qui peuvent être appliqués à l'audio en utilisant <a href="/fr/docs/Web/API/BiquadFilterNode" title="AudioContext.createBiquadFilter()"><code>BiquadFilterNode</code></a>, par exemple:</p>

<p>HTML:</p>

<pre class="brush: html">&lt;video id="my-video" controls src="myvideo.mp4" type="video/mp4"&gt;&lt;/video&gt;</pre>

<p>JavaScript:</p>

<pre class="brush: js">var context     = new AudioContext(),
    audioSource = context.createMediaElementSource(document.getElementById("my-video")),
    filter      = context.createBiquadFilter();
audioSource.connect(filter);
filter.connect(context.destination);

// Configure filter
filter.type = "lowshelf";
filter.frequency.value = 1000;
filter.gain.value = 25;</pre>

<div class="hidden">
<h6 id="Playable_code_2" name="Playable_code_2">Playable code</h6>

<pre class="brush: html">&lt;video id="my-video" controls="true" width="480" height="270" crossorigin="anonymous"&gt;
  &lt;source src="http://jplayer.org/video/webm/Big_Buck_Bunny_Trailer.webm" type="video/webm"&gt;
  &lt;source src="http://jplayer.org/video/m4v/Big_Buck_Bunny_Trailer.m4v" type="video/mp4"&gt;
&lt;/video&gt;
&lt;div class="playable-buttons"&gt;
  &lt;input id="edit" type="button" value="Edit" /&gt;
  &lt;input id="reset" type="button" value="Reset" /&gt;
&lt;/div&gt;
&lt;textarea id="code" class="playable-code"&gt;
filter.type = "lowshelf";
filter.frequency.value = 1000;
filter.gain.value = 25;&lt;/textarea&gt;</pre>

<pre class="brush: js">var context     = new AudioContext(),
    audioSource = context.createMediaElementSource(document.getElementById("my-video")),
    filter      = context.createBiquadFilter();
audioSource.connect(filter);
filter.connect(context.destination);

var textarea = document.getElementById('code');
var reset = document.getElementById('reset');
var edit = document.getElementById('edit');
var code = textarea.value;

function setFilter() {
  eval(textarea.value);
}

reset.addEventListener('click', function() {
  textarea.value = code;
  setFilter();
});

edit.addEventListener('click', function() {
  textarea.focus();
})

textarea.addEventListener('input', setFilter);
window.addEventListener('load', setFilter);
</pre>
</div>

<p><iframe src="https://mdn.mozillademos.org/fr/docs/Web/Guide/Audio_and_video_manipulation$samples/Playable_code_2?revision=1460142" width="700" height="425" frameborder="0" class="live-sample-frame sample-code-frame" id="frame_Playable_code_2"></iframe></p>

<div class="note">
<p><strong>Note</strong>: À moins que <a href="/en-US/docs/Web/HTTP/Access_control_CORS">CORS</a> ne soit activé, vous devrez pour éviter les problèmes de sécurité placer la vidéo sur le même domaine que votre code.</p>
</div>

<p>Les filtres pouvant être appliqués sont:</p>

<ul>
 <li>Low Pass: Les fréquences en dessous de la fréquence de coupure sont inchangées et celles au-dessus sont atténuées.</li>
 <li>High Pass: Les fréquences au-dessus de la fréquence de coupure sont inchangées et celles en dessous sont atténuées.</li>
 <li>Band Pass: Les fréquence comprises entre deux bornes sont inchangées et celles en dehors sont atténuées.</li>
 <li>Low Shelf: Les fréquences basses obtiennent un boost (ou une atténuation).</li>
 <li>High Shelf: Les fréquences hautes obtiennent un boost (ou une atténuation).</li>
 <li>Peaking: Les fréquences à l'intérieur d'une gamme donnée obtiennent un boost (ou une atténuation).</li>
 <li>Notch: Les fréquences à l'intérieur d'une gamme donnée sont atténuées.</li>
 <li>Allpass: Laisse touts les fréquences inchangées mais modifie le rapport de phrase entre les différentes fréquences.</li>
</ul>

<div class="note">
<p><strong>Note</strong>: Voir <a href="/fr/docs/Web/API/BiquadFilterNode" title="AudioContext.createBiquadFilter()"><code>BiquadFilterNode</code></a> pour plus d'informations.</p>
</div>

<h3 id="Convolutions_et_Impulsions">Convolutions et Impulsions</h3>

<p>Il est également possible d'appliquer des réponses impulsionnelles à l'audio en utilisant <a href="/fr/docs/Web/API/ConvolverNode" title="Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant !"><code>ConvolverNode</code></a>. Une <em>réponse impulsionnelle</em> (<em>impulse response</em> en anglais) est un son crée après une brève impulsion sonore (comme un applaudissement) et qui s'applique sur l'environnement qui l'a créée. Exemple: un écho crée en frappant des mains dans un tunnel.</p>

<p>Exemple:</p>

<pre class="brush: js">var convolver = context.createConvolver();
convolver.buffer = this.impulseResponseBuffer;
// Connect the graph.
source.connect(convolver);
convolver.connect(context.destination);</pre>

<div class="note">
<p><strong>Note</strong>: Voir ce <a href="https://codepen.io/DonKarlssonSan/pen/doVKRE">Codepen</a> pour un exemple appliqué.</p>
</div>

<div class="note">
<p><strong>Note</strong>: Voir <a href="/fr/docs/Web/API/ConvolverNode" title="Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant !"><code>ConvolverNode</code></a> pour plus d'informations.</p>
</div>

<h3 id="Audio_dans_l'espace">Audio dans l'espace</h3>

<p>On peut également positionner l'audio dans l'espace en utilisant un noeud panoramique (un <em>panner</em>). Ce noeud permet de définir un cône source ainsi que des éléments positionnels et directionnels — le tout dans un espace 3D définit par des coordonnées cartésiennes 3D.  <br>
 <br>
 Exemple:</p>

<pre class="brush: js">var panner = context.createPanner();
panner.coneOuterGain = 0.2;
panner.coneOuterAngle = 120;
panner.coneInnerAngle = 0;

panner.connect(context.destination);
source.connect(panner);
source.start(0);

// Position the listener at the origin.
context.listener.setPosition(0, 0, 0);</pre>

<div class="note">
<p><strong>Note</strong>: Vous pouvez trouver un <a href="https://github.com/mdn/webaudio-examples/tree/master/panner-node">exemple sur notre repo GitHub</a> (le <a href="https://mdn.github.io/webaudio-examples/panner-node/">voir en direct</a> aussi).</p>
</div>

<div class="note">
<p><strong>Note</strong>: Voir <a href="/fr/docs/Web/API/PannerNode" title="Cette documentation n'a pas encore été rédigée, vous pouvez aider en contribuant !"><code>PannerNode</code></a> pour plus d'informations.</p>
</div>

<h2 id="Codecs_JavaScript">Codecs JavaScript</h2>

<p>Il est possible de manipuler l'audio au bas niveau en utilisant JavaScript. Cela peut être utile si vous voulez créer des codecs audio.<br>
 <br>
 Des bibliothèques existent actuellement pour les formats suivants:</p>

<ul>
 <li>AAC: <a href="https://github.com/audiocogs/aac.js">AAC.js</a></li>
 <li>ALAC: <a href="https://github.com/audiocogs/alac.js">alac.js</a></li>
 <li>FLAC: <a href="https://github.com/audiocogs/flac.js">flac.js</a></li>
 <li>MP3: <a href="https://github.com/audiocogs/mp3.js">mp3.js</a></li>
 <li>Opus: <a href="https://github.com/audiocogs/opus.js">Opus.js</a></li>
 <li>Vorbis: <a href="https://github.com/audiocogs/vorbis.js">vorbis.js</a></li>
</ul>

<div class="note">
<p><strong>Note</strong>: Sur AudioCogs, vous pouvez <a href="http://audiocogs.org/codecs/">essayer quelques démos</a>; Audiocogs fournit également un Framework, <a href="http://audiocogs.org/codecs/">Aurora.js</a>, qui est destiné à vous aider à créer vos propres codecs en JavaScript.</p>
</div>

<h2 id="Tutoriels">Tutoriels</h2>

<ul>
 <li><a href="/fr/docs/HTML/Manipulating_video_using_canvas">Manipulation vidéo avec la balise Canvas</a></li>
 <li><a href="/fr/Apps/Build/Manipulating_media/HTML5_playbackRate_explained">HTML5 playbackRate expliqué</a></li>
 <li><a href="/fr/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Utiliser l'API Web Audio</a></li>
 <li><a href="/fr/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics">Les bases de la spatialisation audio Web</a></li>
 <li><a href="/fr/docs/Web/API/WebGL_API/Tutorial/Animation_de_textures_en_WebGL#Utilisation_des_images_vid%C3%A9o_comme_texture">Utilisation des images vidéo comme texture WebGL</a> (Vous pouvez également utiliser la bilbiothèque WebGL <a href="http://threejs.org">THREE.js</a> (ou autres) pour <a href="http://stemkoski.github.io/Three.js/Video.html">obtenir cet effet</a>)</li>
 <li><a href="/fr/docs/Web/API/WebGL_API/Tutorial/Animation_de_textures_en_WebGL">Animation de Textures en WebGL</a></li>
 <li><a href="http://www.html5rocks.com/en/tutorials/webaudio/games/#toc-room">Developing Game Audio with the Web Audio API (Room effects and filters)</a></li>
</ul>

<h2 id="Référence">Référence</h2>

<ul>
 <li>Les éléments <a href="/fr/docs/Web/HTML/Element/audio" title="L'élément HTML &lt;audio> est utilisé afin d'intégrer un contenu sonore dans un document. Il peut contenir une ou plusieurs sources audio représentées avec l'attribut src ou l'élément &lt;source>. S'il y a plusieurs sources, l'agent utilisateur choisira celle qui convient le mieux."><code>&lt;audio&gt;</code></a> et <a href="/fr/docs/Web/HTML/Element/video" title="L'élément HTML &lt;video> intègre un contenu vidéo dans un document."><code>&lt;video&gt;</code></a></li>
 <li>L'API <a href="/fr/docs/Web/API/HTMLMediaElement" title="L'interface HTMLMediaElement ajoute à HTMLElement les propriétés et les méthodes nécessaires pour prendre en charge les fonctionnalités de base liées aux médias qui sont communes aux vidéos et aux documents audios. HTMLVideoElement et HTMLAudioElement héritent de cette interface."><code>HTMLMediaElement</code></a></li>
 <li>L'élément <a href="/fr/docs/Web/HTML/Element/canvas" title="L'élément &lt;canvas> permet de modifier une zone graphique via un script (habituellement en JavaScript ou grâce à WebGL). Il peut par exemple être utilisé afin de dessiner des graphiques, manipuler des images ou jouer des animations."><code>&lt;canvas&gt;</code></a></li>
 <li><a href="/fr/docs/Web/API/Web_Audio_API">Web Audio API</a></li>
 <li><a href="/fr/docs/Web/API/AudioContext">AudioContext</a></li>
 <li>Plus d'infos sur <a href="/fr/docs/Web/API/AudioContext.createPanner">PannerNode</a></li>
</ul>
