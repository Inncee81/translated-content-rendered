---
title: BaseAudioContext.createBuffer()
slug: Web/API/BaseAudioContext/createBuffer
tags:
  - API
  - AudioContext
  - BaseAudioContext
  - Method
  - Reference
  - Web Audio API
  - createBuffer
translation_of: Web/API/BaseAudioContext/createBuffer
---
<p></p><section class="Quick_links" id="Quick_Links"><ol><li><strong><a href="/fr/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a></strong></li><li class="toggle"><details open><summary>Propriétés</summary><ol><li><a href="/fr/docs/Web/API/BaseAudioContext/currentTime"><code>currentTime</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/currentTime$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/destination"><code>destination</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/destination$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/listener"><code>listener</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/listener$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/sampleRate"><code>sampleRate</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/sampleRate$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/state"><code>state</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/state$translate">[Traduire]</a></li></ol></details></li><li class="toggle"><details open><summary>Méthodes</summary><ol><li><a href="/fr/docs/Web/API/BaseAudioContext/createAnalyser"><code>createAnalyser()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createAnalyser$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createBiquadFilter"><code>createBiquadFilter()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createBiquadFilter$translate">[Traduire]</a></li><li><em><code>createBuffer()</code></em></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createBufferSource"><code>createBufferSource()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createBufferSource$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createChannelMerger"><code>createChannelMerger()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createChannelMerger$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createChannelSplitter"><code>createChannelSplitter()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createChannelSplitter$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createConstantSource"><code>createConstantSource()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createConstantSource$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createConvolver"><code>createConvolver()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createConvolver$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createDelay"><code>createDelay()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createDelay$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createDynamicsCompressor"><code>createDynamicsCompressor()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createDynamicsCompressor$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/AudioContext/createGain"><code>createGain()</code></a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createIIRFilter"><code>createIIRFilter()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createIIRFilter$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createOscillator"><code>createOscillator()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createOscillator$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createPanner"><code>createPanner()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createPanner$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createPeriodicWave"><code>createPeriodicWave()</code></a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createScriptProcessor"><code>createScriptProcessor()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createScriptProcessor$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createStereoPanner"><code>createStereoPanner()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createStereoPanner$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/createWaveShaper"><code>createWaveShaper()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/createWaveShaper$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/decodeAudioData"><code>decodeAudioData()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/decodeAudioData$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/BaseAudioContext/resume"><code>resume()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/BaseAudioContext/resume$translate">[Traduire]</a></li></ol></details></li><li class="toggle"><details open><summary>Héritage :</summary><ol><li><a href="/fr/docs/Web/API/EventTarget"><code>EventTarget</code></a></li></ol></details></li></ol></section><p></p>

<p>La méthode <code>createBuffer()</code> de l&apos;interface <a href="/fr/docs/Web/API/BaseAudioContext" title="The BaseAudioContext interface acts as a base definition for online and offline audio-processing graphs, as represented by AudioContext and OfflineAudioContext respectively."><code>BaseAudioContext</code></a> est utilisée pour créer un nouvel objet <a href="/fr/docs/Web/API/AudioBuffer" title="L&apos;interface AudioBuffer représente une ressource audio stockée en mémoire, créée à partir d&apos;un fichier audio avec la méthode AudioContext.decodeAudioData(), ou à partir de données brutes avec AudioContext.createBuffer(). Une fois mises en mémoire dans un AudioBuffer, les données audio sont transférées dans un AudioBufferSourceNode afin d&apos;être lues.

 Ce type d&apos;objet est conçu pour contenir de petit extraits audio, durant généralement moins de 45s. Pour les sons plus longs, les objets implémentant MediaAudioElementSourceNode sont plus adaptés. La mémoire tampon contient des données au format non entrelacé IEEE 32-bit PCM linéaire, avec une portée nominale comprise entre -1 et +1. S&apos;il y a plusieurs canaux, ils sont stockés dans des mémoires-tampon distinctes."><code>AudioBuffer</code></a> vide, qui peut ensuite être rempli.</p>

<p>Pour plus de détails sur les tampons audio, consultez la page de référence <a href="/fr/docs/Web/API/AudioBuffer" title="L&apos;interface AudioBuffer représente une ressource audio stockée en mémoire, créée à partir d&apos;un fichier audio avec la méthode AudioContext.decodeAudioData(), ou à partir de données brutes avec AudioContext.createBuffer(). Une fois mises en mémoire dans un AudioBuffer, les données audio sont transférées dans un AudioBufferSourceNode afin d&apos;être lues.

 Ce type d&apos;objet est conçu pour contenir de petit extraits audio, durant généralement moins de 45s. Pour les sons plus longs, les objets implémentant MediaAudioElementSourceNode sont plus adaptés. La mémoire tampon contient des données au format non entrelacé IEEE 32-bit PCM linéaire, avec une portée nominale comprise entre -1 et +1. S&apos;il y a plusieurs canaux, ils sont stockés dans des mémoires-tampon distinctes."><code>AudioBuffer</code></a>.</p>

<div class="note notecard">
<p><strong>Note :</strong> <code>createBuffer()</code> permettait de prendre des données compressées et de restituer des échantillons décodés, mais cette possibilité a été supprimée de la spécification, du fait que tout le décodage était effectué dans le thread principal, donc <code>createBuffer()</code> bloquait l&apos;exécution du reste du code. La méthode asynchrone <code>decodeAudioData()</code> fait la même chose - prend l&apos;audio compressé, par exemple, un fichier MP3, et vous renvoie directement un <a href="/fr/docs/Web/API/AudioBuffer" title="L&apos;interface AudioBuffer représente une ressource audio stockée en mémoire, créée à partir d&apos;un fichier audio avec la méthode AudioContext.decodeAudioData(), ou à partir de données brutes avec AudioContext.createBuffer(). Une fois mises en mémoire dans un AudioBuffer, les données audio sont transférées dans un AudioBufferSourceNode afin d&apos;être lues.

 Ce type d&apos;objet est conçu pour contenir de petit extraits audio, durant généralement moins de 45s. Pour les sons plus longs, les objets implémentant MediaAudioElementSourceNode sont plus adaptés. La mémoire tampon contient des données au format non entrelacé IEEE 32-bit PCM linéaire, avec une portée nominale comprise entre -1 et +1. S&apos;il y a plusieurs canaux, ils sont stockés dans des mémoires-tampon distinctes."><code>AudioBuffer</code></a> que vous pouvez ensuite faire jouer via <a href="/fr/docs/Web/API/AudioBufferSourceNode" title="L&apos;interface AudioBufferSourceNode est un AudioScheduledSourceNode qui représente une source audio constituée de données audio en mémoire, stockées dans un AudioBuffer. Elle est particulièrement utile pour lire des sons qui requierrent des conditions de lecture particulières, comme la synchronisation sur un certain rythme, et peuvent être stockés en mémoire. Si ce type de son doit être lu depuis le disque ou le réseau, il conviendra d&apos;utiliser un AudioWorkletNode. "><code>AudioBufferSourceNode</code></a>. Pour des utilisations simples comme la lecture d&apos;un fichier MP3, <code>decodeAudioData()</code> est ce que vous devriez utiliser.</p>
</div>

<h2 id="Syntaxe">Syntaxe</h2>

<pre class="syntaxbox">var tampon = baseAudioContext.createBuffer(<em>nbDeCanaux</em>, <em>longueur</em>, <em>frequenceDEchantillonnage</em>);</pre>

<h3 id="Paramètres">Paramètres</h3>

<div class="note notecard">
<p><strong>Note :</strong> pour une explication en profondeur de la façon dont les tampons audio fonctionnent, ainsi que de leur signification, lire <a href="/fr/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API">Les concepts de base de la Web Audio API</a> de notre guide des concepts de base.</p>
</div>

<dl>
 <dt>nbDeCanaux</dt>
 <dd>Un nombre entier représentant le nombre de canaux que ce tampon doit avoir. Les implémentations doivent prendre en charge un minimum de 1 canal et un maximum de 32 canaux.</dd>
 <dt>longueur</dt>
 <dd><span lang="fr" id="result_box"><span class="alt-edited">Un entier représentant la taille du tampon dans les trames d&apos;échantillons.</span></span></dd>
 <dt>frequenceDEchantillonnage</dt>
 <dd>La fréquence d&apos;échantillonnage des données audio linéaires en trames d&apos;échantillons par seconde. Une implémentation doit supporter des fréquences d&apos;échantillonnage comprises au minimum dans la plage 22050 et 96000.</dd>
</dl>

<h3 id="Retourne">Retourne</h3>

<p>Un <a href="/fr/docs/Web/API/AudioBuffer" title="L&apos;interface AudioBuffer représente une ressource audio stockée en mémoire, créée à partir d&apos;un fichier audio avec la méthode AudioContext.decodeAudioData(), ou à partir de données brutes avec AudioContext.createBuffer(). Une fois mises en mémoire dans un AudioBuffer, les données audio sont transférées dans un AudioBufferSourceNode afin d&apos;être lues.

 Ce type d&apos;objet est conçu pour contenir de petit extraits audio, durant généralement moins de 45s. Pour les sons plus longs, les objets implémentant MediaAudioElementSourceNode sont plus adaptés. La mémoire tampon contient des données au format non entrelacé IEEE 32-bit PCM linéaire, avec une portée nominale comprise entre -1 et +1. S&apos;il y a plusieurs canaux, ils sont stockés dans des mémoires-tampon distinctes."><code>AudioBuffer</code></a>.</p>

<h2 id="Exemples">Exemples</h2>

<p>Tout d&apos;abord, deux exemples triviaux simples pour aider à expliquer comment les paramètres sont utilisés :</p>

<pre class="brush: js">var ctxAudio = new AudioContext();
var tampon = ctxAudio.createBuffer(2, 22050, 44100);</pre>

<p>Si vous utilisez cet appel, vous obtiendrez un tampon stéréo (deux canaux), qui, lorsque relu avec un <code>AudioContext</code> fonctionnant à 44100Hz (très courant, la plupart des cartes son normales fonctionnent à cette fréquence), durera 0,5 seconde : 22050 trames / 44100 Hz = 0,5 seconde.</p>

<pre class="brush: js">var ctxAudio = new AudioContext();
var tampon = ctxAudio.createBuffer(1, 22050, 22050);</pre>

<p>Si vous utilisez cet appel, vous obtiendrez un tampon mono (un canal), qui, lorsqu&apos;il sera relu avec un <code>AudioContext</code> fonctionnant à 44100Hz, sera automatiquement *rééchantillonné* à 44100Hz (et produira donc 44100 trames), et durera 1,0 seconde : 44100 images / 44100Hz = 1 seconde.</p>

<div class="note notecard">
<p><strong>Note :</strong> le rééchantillonnage audio est très similaire au redimensionnement d&apos;une image : supposons que vous ayez une image 16 x 16, mais que vous vouliez qu&apos;elle remplisse une zone 32x32: vous la redimensionnez (rééchantillonnez). Le résultat aura une qualité moindre (il pourra être flou ou bizarre, selon l&apos;algorithme de redimensionnement), mais cela fonctionnera, et l&apos;image redimensionnée prendra moins de place. L&apos;audio rééchantillonné est exactement la même chose - vous économisez de l&apos;espace, mais en pratique, vous ne pourrez pas reproduire correctement le contenu haute fréquence (les sons aigus).</p>
</div>

<p>Examinons maintenant un exemple de <code>createBuffer()</code> plus complexe, dans lequel nous créons un tampon de deux secondes, le remplissons de bruit blanc, puis le reproduisons via <a href="/fr/docs/Web/API/AudioBufferSourceNode" title="L&apos;interface AudioBufferSourceNode est un AudioScheduledSourceNode qui représente une source audio constituée de données audio en mémoire, stockées dans un AudioBuffer. Elle est particulièrement utile pour lire des sons qui requierrent des conditions de lecture particulières, comme la synchronisation sur un certain rythme, et peuvent être stockés en mémoire. Si ce type de son doit être lu depuis le disque ou le réseau, il conviendra d&apos;utiliser un AudioWorkletNode. "><code>AudioBufferSourceNode</code></a>. Le commentaire devrait clairement faire comprendre ce qui se passe. Vous pouvez également exécuter le code en direct ou regarder le source.</p>

<pre class="brush: js;highlight[14]">var ctxAudio = new (window.AudioContext || window.webkitAudioContext)();

// Création d&apos;un tampon stéréo vide de trois secondes à la fréquence d&apos;échantillonnage de l&apos;AudioContext
var monArrayBuffer = ctxAudio.createBuffer(2, ctxAudio.sampleRate * 3, ctxAudio.sampleRate);

// Remplissage du tampon avec du bruit blanc ;
// simplement des valeurs aléatoires entre -1,0 et 1,0
for (var canal = 0; canal &lt; monArrayBuffer.numberOfChannels; canal++) {
  // Cela nous donne le ArrayBuffer qui contient effectivement les données
  var donneesCourantes = monArrayBuffer.getChannelData(canal);
  for (var i = 0; i &lt; monArrayBuffer.length; i++) {
    // Math.random() est dans [0; 1,0]
    // l&apos;audio doit se trouver dans [-1,0; 1,0]
    donneesCourantes[i] = Math.random() * 2 - 1;
  }
}

// Récupération d&apos;un AudioBufferSourceNode.
// C&apos;est l&apos;AudioNode à utiliser quand nous voulons lire un AudioBuffer
var source = ctxAudio.createBufferSource();
// Définir le tampon dans l&apos;AudioBufferSourceNode
source.buffer = monArrayBuffer;
// Connecter l&apos;AudioBufferSourceNode à la destination,
// de sorte que nous puissions entendre le son
source.connect(ctxAudio.destination);
// Démarrer la lecture de la source
source.start();</pre>

<h2 id="Spécifications">Spécifications</h2>

<table class="standard-table">
 <tbody>
  <tr>
   <th scope="col">Spécification</th>
   <th scope="col">Statut</th>
   <th scope="col">Commentaire</th>
  </tr>
  <tr>
   <td><a lang="en" href="https://webaudio.github.io/web-audio-api/#dom-baseaudiocontext-createbuffer" class="external" hreflang="en">Web Audio API<br><small lang="fr">La définition de &apos;createBuffer()&apos; dans cette spécification.</small></a></td>
   <td><span class="spec-WD">Version de travail</span></td>
   <td> </td>
  </tr>
 </tbody>
</table>

<h2 id="Compatibilité_des_navigateurs">Compatibilité des navigateurs</h2>

<div><div class="warning notecard"><strong><a href="https://github.com/mdn/browser-compat-data">Nous convertissons les données de compatibilité dans un format JSON</a></strong>.
            Ce tableau de compatibilité utilise encore l&apos;ancien format
            car nous n&apos;avons pas encore converti les données qu&apos;il contient.
            <strong><a href="/fr/docs/MDN/Contribute/Structures/Compatibility_tables">Vous pouvez nous aider en contribuant !</a></strong></div>

<div class="htab">
    <a id="AutoCompatibilityTable" name="AutoCompatibilityTable"></a>
    <ul>
        <li class="selected"><a>Ordinateur</a></li>
        <li><a>Mobile</a></li>
    </ul>
</div></div>

<div id="compat-desktop">
<table class="compat-table">
 <tbody>
  <tr>
   <th>Feature</th>
   <th>Chrome</th>
   <th>Edge</th>
   <th>Firefox (Gecko)</th>
   <th>Internet Explorer</th>
   <th>Opera</th>
   <th>Safari (WebKit)</th>
  </tr>
  <tr>
   <td>Basic support</td>
   <td>10.0<span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/fr/docs/Web/Guide/Prefixes">webkit</a></span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><a href="/en-US/Firefox/Releases/25">25.0</a> (25.0) </td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td>15.0 <span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/fr/docs/Web/Guide/Prefixes">webkit</a></span><br>
    22</td>
   <td>6.0<span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/fr/docs/Web/Guide/Prefixes">webkit</a></span></td>
  </tr>
 </tbody>
</table>
</div>

<div id="compat-mobile">
<table class="compat-table">
 <tbody>
  <tr>
   <th>Feature</th>
   <th>Android</th>
   <th>Edge</th>
   <th>Firefox Mobile (Gecko)</th>
   <th>Firefox OS</th>
   <th>IE Mobile</th>
   <th>Opera Mobile</th>
   <th>Safari Mobile</th>
   <th>Chrome for Android</th>
  </tr>
  <tr>
   <td>Basic support</td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td>26.0</td>
   <td>1.2</td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td>33.0</td>
  </tr>
 </tbody>
</table>
</div>

<h2 id="Voir_aussi">Voir aussi</h2>

<ul>
 <li><a href="/fr/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Utilisation de l&apos;API Web Audio</a></li>
</ul>
