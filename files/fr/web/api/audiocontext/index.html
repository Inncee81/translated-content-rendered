---
title: AudioContext
slug: Web/API/AudioContext
tags:
  - API
  - Audio
  - Buffer
  - Experimental
  - Reference
  - Web Audio API
translation_of: Web/API/AudioContext
---
<p></p><section class="Quick_links" id="Quick_Links"><ol><li><strong><a href="/fr/docs/Web/API/Web_Audio_API">Web Audio API</a></strong></li><li><strong><a href="/fr/docs/Web/API/AudioContext"><code>AudioContext</code></a></strong></li><li class="toggle"><details open><summary>Constructeur</summary><ol><li><a href="/fr/docs/Web/API/AudioContext/AudioContext"><code>AudioContext()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/AudioContext$translate">[Traduire]</a></li></ol></details></li><li class="toggle"><details open><summary>Propriétés</summary><ol><li><span class="sidebar-icon"><span title="This is an experimental API that should not be used in production code."><i class="icon-beaker"> </i></span></span><a href="/fr/docs/Web/API/AudioContext/baseLatency"><code>baseLatency</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/baseLatency$translate">[Traduire]</a></li><li><span class="sidebar-icon"><span title="This is an experimental API that should not be used in production code."><i class="icon-beaker"> </i></span></span><a href="/fr/docs/Web/API/AudioContext/outputLatency"><code>outputLatency</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/outputLatency$translate">[Traduire]</a></li></ol></details></li><li class="toggle"><details open><summary>Méthodes</summary><ol><li><a href="/fr/docs/Web/API/AudioContext/close"><code>close()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/close$translate">[Traduire]</a></li><li><span class="sidebar-icon"><span class="icon-only-inline" title="This is an obsolete API and is no longer guaranteed to work."><i class="icon-trash"> </i></span></span><s class="obsoleteElement"><a href="/fr/docs/Web/API/AudioContext/createJavaScriptNode"><code>createJavaScriptNode()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/createJavaScriptNode$translate">[Traduire]</a></s></li><li><a href="/fr/docs/Web/API/AudioContext/createMediaElementSource"><code>createMediaElementSource()</code></a></li><li><a href="/fr/docs/Web/API/AudioContext/createMediaStreamDestination"><code>createMediaStreamDestination()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/createMediaStreamDestination$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/AudioContext/createMediaStreamSource"><code>createMediaStreamSource()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/createMediaStreamSource$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/AudioContext/createMediaStreamTrackSource"><code>createMediaStreamTrackSource()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/createMediaStreamTrackSource$translate">[Traduire]</a></li><li><span class="sidebar-icon"><span class="icon-only-inline" title="This is an obsolete API and is no longer guaranteed to work."><i class="icon-trash"> </i></span></span><s class="obsoleteElement"><a href="/fr/docs/Web/API/AudioContext/createWaveTable"><code>createWaveTable()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/createWaveTable$translate">[Traduire]</a></s></li><li><a href="/fr/docs/Web/API/AudioContext/getOutputTimestamp"><code>getOutputTimestamp()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/getOutputTimestamp$translate">[Traduire]</a></li><li><a href="/fr/docs/Web/API/AudioContext/suspend"><code>suspend()</code></a> <a style="opacity: 0.5;" href="/fr/docs/Web/API/AudioContext/suspend$translate">[Traduire]</a></li></ol></details></li><li class="toggle"><details open><summary>Héritage :</summary><ol><li><a href="/fr/docs/Web/API/EventTarget"><code>EventTarget</code></a></li></ol></details></li><li class="toggle"><details open><summary>Événements</summary><ol><li><a href="/fr/docs/Web/Events/statechange"><code>statechange</code></a></li><li><a href="/fr/docs/Web/Events/complete"><code>complete</code></a></li><li><a href="/fr/docs/Web/Events/ended"><code>ended</code></a></li><li><a href="/fr/docs/Web/Events/message"><code>message</code></a></li><li><a href="/fr/docs/Web/Events/loaded"><code>loaded</code></a></li><li><a href="/fr/docs/Web/Events/audioprocess"><code>audioprocess</code></a></li><li><a href="/fr/docs/Web/Events/nodecreate"><code>nodecreate</code></a></li></ol></details></li><li class="toggle"><details open><summary>Pages liées à Web Audio API</summary><ol><li><a href="/fr/docs/Web/API/AnalyserNode"><code>AnalyserNode</code></a></li><li><a href="/fr/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a></li><li><a href="/fr/docs/Web/API/AudioBufferSourceNode"><code>AudioBufferSourceNode</code></a></li><li><a href="/fr/docs/Web/API/AudioContextOptions"><code>AudioContextOptions</code></a></li><li><a href="/fr/docs/Web/API/AudioDestinationNode"><code>AudioDestinationNode</code></a></li><li><a href="/fr/docs/Web/API/AudioListener"><code>AudioListener</code></a></li><li><a href="/fr/docs/Web/API/AudioNode"><code>AudioNode</code></a></li><li><a href="/fr/docs/Web/API/AudioNodeOptions"><code>AudioNodeOptions</code></a></li><li><a href="/fr/docs/Web/API/AudioParam"><code>AudioParam</code></a></li><li><a href="/fr/docs/Web/API/AudioProcessingEvent"><code>AudioProcessingEvent</code></a></li><li><a href="/fr/docs/Web/API/AudioScheduledSourceNode"><code>AudioScheduledSourceNode</code></a></li><li><a href="/fr/docs/Web/API/BaseAudioContext"><code>BaseAudioContext</code></a></li><li><a href="/fr/docs/Web/API/BiquadFilterNode"><code>BiquadFilterNode</code></a></li><li><a href="/fr/docs/Web/API/ChannelMergerNode"><code>ChannelMergerNode</code></a></li><li><a href="/fr/docs/Web/API/ChannelSplitterNode"><code>ChannelSplitterNode</code></a></li><li><a href="/fr/docs/Web/API/ConstantSourceNode"><code>ConstantSourceNode</code></a></li><li><a href="/fr/docs/Web/API/ConvolverNode"><code>ConvolverNode</code></a></li><li><a href="/fr/docs/Web/API/DelayNode"><code>DelayNode</code></a></li><li><a href="/fr/docs/Web/API/DynamicsCompressorNode"><code>DynamicsCompressorNode</code></a></li><li><a href="/fr/docs/Web/API/GainNode"><code>GainNode</code></a></li><li><a href="/fr/docs/Web/API/IIRFilterNode"><code>IIRFilterNode</code></a></li><li><a href="/fr/docs/Web/API/MediaElementAudioSourceNode"><code>MediaElementAudioSourceNode</code></a></li><li><a href="/fr/docs/Web/API/MediaStreamAudioDestinationNode"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href="/fr/docs/Web/API/MediaStreamAudioSourceNode"><code>MediaStreamAudioSourceNode</code></a></li><li><a href="/fr/docs/Web/API/OfflineAudioCompletionEvent"><code>OfflineAudioCompletionEvent</code></a></li><li><a href="/fr/docs/Web/API/OfflineAudioContext"><code>OfflineAudioContext</code></a></li><li><a href="/fr/docs/Web/API/OscillatorNode"><code>OscillatorNode</code></a></li><li><a href="/fr/docs/Web/API/PannerNode"><code>PannerNode</code></a></li><li><a href="/fr/docs/Web/API/PeriodicWave"><code>PeriodicWave</code></a></li><li><a href="/fr/docs/Web/API/StereoPannerNode"><code>StereoPannerNode</code></a></li><li><a href="/fr/docs/Web/API/WaveShaperNode"><code>WaveShaperNode</code></a></li></ol></details></li></ol></section><p></p>

<p>L&apos;interface AudioContext représente un graphe de traitement audio fait de modules audio reliés entre eux, chaque module correspondant à un <a href="/fr/docs/Web/API/AudioNode" title="L&apos;interface AudioNode est une interface générique pour représenter un module de traitement audio tel qu&apos;une source audio &lt;audio&gt;, un élément &lt;video&gt;, un OscillatorNode, une sortie audio, ou un module de traitement intermédiaire  (filtres BiquadFilterNode ou ConvolverNode), un contrôle de volume GainNode."><code>AudioNode</code></a>. Un contexte audio contrôle à la fois la création des nœuds qu&apos;il contient et l&apos;exécution du traitement audio, ou du décodage. On commence toujours par créer un contexte audio, et tout ce qui va se passer ensuite se situera dans ce contexte.</p>

<p>Un contexte audio peut être la cible d&apos;événements, par conséquent il implémente l&apos;interface <a href="/fr/docs/Web/API/EventTarget" title="EventTarget est une interface implémentée par des objets qui peuvent recevoir des évènements et avoir des auditeurs."><code>EventTarget</code></a>.</p>

<p></p><div class="hidden" id="inheritance_diagram">

<pre class="brush: html">  &lt;div id=&quot;interfaceDiagram&quot; style=&quot;display: inline-block; position: relative; width: 100%; padding-bottom: 11.666666666666666%; vertical-align: middle; overflow: hidden;&quot;&gt;&lt;svg style=&quot;display: inline-block; position: absolute; top: 0; left: 0;&quot; viewbox=&quot;-50 0 600 70&quot; preserveAspectRatio=&quot;xMinYMin meet&quot;&gt;&lt;a xlink:href=&quot;https://developer.mozilla.org/fr/docs/Web/API/EventTarget&quot; target=&quot;_top&quot;&gt;&lt;rect x=&quot;1&quot; y=&quot;1&quot; width=&quot;110&quot; height=&quot;50&quot; fill=&quot;#fff&quot; stroke=&quot;#D4DDE4&quot; stroke-width=&quot;2px&quot; /&gt;&lt;text  x=&quot;56&quot; y=&quot;30&quot; font-size=&quot;12px&quot; font-family=&quot;Consolas,Monaco,Andale Mono,monospace&quot; fill=&quot;#4D4E53&quot; text-anchor=&quot;middle&quot; alignment-baseline=&quot;middle&quot;&gt;EventTarget&lt;/text&gt;&lt;/a&gt;&lt;polyline points=&quot;111,25  121,20  121,30  111,25&quot; stroke=&quot;#D4DDE4&quot; fill=&quot;none&quot;/&gt;&lt;line x1=&quot;121&quot; y1=&quot;25&quot; x2=&quot;151&quot; y2=&quot;25&quot; stroke=&quot;#D4DDE4&quot;/&gt;&lt;a xlink:href=&quot;https://developer.mozilla.org/fr/docs/Web/API/AudioContext&quot; target=&quot;_top&quot;&gt;&lt;rect x=&quot;151&quot; y=&quot;1&quot; width=&quot;120&quot; height=&quot;50&quot; fill=&quot;#F4F7F8&quot; stroke=&quot;#D4DDE4&quot; stroke-width=&quot;2px&quot; /&gt;&lt;text  x=&quot;211&quot; y=&quot;30&quot; font-size=&quot;12px&quot; font-family=&quot;Consolas,Monaco,Andale Mono,monospace&quot; fill=&quot;#4D4E53&quot; text-anchor=&quot;middle&quot; alignment-baseline=&quot;middle&quot;&gt;AudioContext&lt;/text&gt;&lt;/a&gt;&lt;/svg&gt;&lt;/div&gt;
</pre>

<pre class="brush: css">  a:hover text { fill: #0095DD; pointer-events: all;}
</pre>

</div>

<iframe src="https://mdn.mozillademos.org/fr/docs/Web/API/AudioContext$samples/inheritance_diagram?revision=1268059" width="600" height="70" frameborder="0" class="live-sample-frame inheritance-diagram-frame" id="frame_inheritance_diagram"></iframe><p></p>

<h2 id="Constructeur">Constructeur</h2>

<dl>
 <dt><a href="/fr/docs/Web/API/AudioContext/AudioContext" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext()</code></a></dt>
 <dd>Crée et retourne un nouvel objet <code>AudioContext</code>.</dd>
</dl>

<h2 id="Propriétés">Propriétés</h2>

<dl>
 <dt><a href="/fr/docs/Web/API/AudioContext/currentTime" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.currentTime</code></a> <span class="readOnly readOnlyInline notecard inline" title="Cette valeur ne peut pas être changée.">Lecture seule </span></dt>
 <dd>Renvoie un double flottant, qui représente un temps en secondes en augmentation continue, utilisé pour situer dans le temps. Il commence à <code>0</code>.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/destination" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.destination</code></a> <span class="readOnly readOnlyInline notecard inline" title="Cette valeur ne peut pas être changée.">Lecture seule </span></dt>
 <dd>Retourne un <a href="/fr/docs/Web/API/AudioDestinationNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioDestinationNode</code></a> représentant la destination finale de tous les fichiers audio dans un contexte. On peut le considérer comme un dispositif de rendu audio.</dd>
</dl>

<dl>
 <dt><a href="/fr/docs/Web/API/AudioContext/listener" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.listener</code></a> <span class="readOnly readOnlyInline notecard inline" title="Cette valeur ne peut pas être changée.">Lecture seule </span></dt>
 <dd>Renvoie l&apos;objet <a href="/fr/docs/Web/API/AudioListener" title="L&apos;interface AudioListener représente la position et l&apos;orientation de l&apos;unique personne écoutant la scène audio; elle est utilisée dans le cadre d&apos;une spatialisation audio. Tous les PannerNode sont spatialisés par rapport à l&apos;objet AudioListener stocké dans la propriété AudioContext.listener."><code>AudioListener</code></a>, utilisé pour la spatialisation 3D.</dd>
</dl>

<dl>
 <dt><a href="/fr/docs/Web/API/AudioContext/sampleRate" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.sampleRate</code></a> <span class="readOnly readOnlyInline notecard inline" title="Cette valeur ne peut pas être changée.">Lecture seule </span></dt>
 <dd>Renvoie un nombre flottant représentant la fréquence d&apos;échantillonnage (échantillons par seconde) utilisée par tous les nœuds dans ce contexte.La fréquence d&apos;échantillonnage d&apos;un contexte audio ne peut pas être modifiée.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/state" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.state</code></a> <span class="readOnly readOnlyInline notecard inline" title="Cette valeur ne peut pas être changée.">Lecture seule </span></dt>
 <dd>Renvoie l&apos;état actuel du contexte audio.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/mozAudioChannelType" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.mozAudioChannelType</code></a> <span class="icon-only-inline" title="Cette API n&apos;a pas été standardisée."><i class="icon-warning-sign"> </i></span> <span class="readOnly readOnlyInline notecard inline" title="Cette valeur ne peut pas être changée.">Lecture seule </span></dt>
 <dd>Sur Firefox OS, utilisé pour renvoyer la piste audio dans laquelle sera jouée le son qui sera lancé dans le contexte audio.</dd>
</dl>

<h3 id="Event_handlers">Event handlers</h3>

<dl>
 <dt><a href="/fr/docs/Web/API/AudioContext/onstatechange" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.onstatechange</code></a></dt>
 <dd>Un gestionnaire d&apos;évènement déclenché par un évènement du type <code><a href="/fr/docs/Web/Reference/Events/statechange" title="/fr/docs/Web/Reference/Events/statechange">statechange</a></code>. Cela a lieu quand l&apos;état du contexte audio change, en raison de l&apos;appel des méthodes de changement d&apos;état (<a href="/fr/docs/Web/API/AudioContext/suspend" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.suspend</code></a>, <a href="/fr/docs/Web/API/AudioContext/resume" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.resume</code></a>, ou <a href="/fr/docs/Web/API/AudioContext/close" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.close</code></a>.)</dd>
</dl>

<h2 id="Méthodes">Méthodes</h2>

<p><em>Met également en œuvre des méthodes de l&apos;interface <a href="/fr/docs/Web/API/EventTarget" title="EventTarget est une interface implémentée par des objets qui peuvent recevoir des évènements et avoir des auditeurs."><code>EventTarget</code></a>.</em></p>

<dl>
 <dt><a href="/fr/docs/Web/API/AudioContext/close" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.close()</code></a></dt>
 <dd>Supprime le contexte audio, et libère toutes les ressources audio système qu&apos;il utilisait.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createBuffer" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createBuffer()</code></a></dt>
 <dd>Crée un nouvel objet <a href="/fr/docs/Web/API/AudioBuffer" title="L&apos;interface AudioBuffer représente une ressource audio stockée en mémoire, créée à partir d&apos;un fichier audio avec la méthode AudioContext.decodeAudioData(), ou à partir de données brutes avec AudioContext.createBuffer(). Une fois mises en mémoire dans un AudioBuffer, les données audio sont transférées dans un AudioBufferSourceNode afin d&apos;être lues.

 Ce type d&apos;objet est conçu pour contenir de petit extraits audio, durant généralement moins de 45s. Pour les sons plus longs, les objets implémentant MediaAudioElementSourceNode sont plus adaptés. La mémoire tampon contient des données au format non entrelacé IEEE 32-bit PCM linéaire, avec une portée nominale comprise entre -1 et +1. S&apos;il y a plusieurs canaux, ils sont stockés dans des mémoires-tampon distinctes."><code>AudioBuffer</code></a> vide, auquel on pourra assigner des données et que l&apos;on pourra jouer via un <a href="/fr/docs/Web/API/AudioBufferSourceNode" title="L&apos;interface AudioBufferSourceNode est un AudioScheduledSourceNode qui représente une source audio constituée de données audio en mémoire, stockées dans un AudioBuffer. Elle est particulièrement utile pour lire des sons qui requierrent des conditions de lecture particulières, comme la synchronisation sur un certain rythme, et peuvent être stockés en mémoire. Si ce type de son doit être lu depuis le disque ou le réseau, il conviendra d&apos;utiliser un AudioWorkletNode. "><code>AudioBufferSourceNode</code></a></dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createBufferSource" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createBufferSource()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/AudioBufferSourceNode" title="L&apos;interface AudioBufferSourceNode est un AudioScheduledSourceNode qui représente une source audio constituée de données audio en mémoire, stockées dans un AudioBuffer. Elle est particulièrement utile pour lire des sons qui requierrent des conditions de lecture particulières, comme la synchronisation sur un certain rythme, et peuvent être stockés en mémoire. Si ce type de son doit être lu depuis le disque ou le réseau, il conviendra d&apos;utiliser un AudioWorkletNode. "><code>AudioBufferSourceNode</code></a>, qui peut être utilisé pour jouer et manipuler des données audio contenues dans un objet <a href="/fr/docs/Web/API/AudioBuffer" title="L&apos;interface AudioBuffer représente une ressource audio stockée en mémoire, créée à partir d&apos;un fichier audio avec la méthode AudioContext.decodeAudioData(), ou à partir de données brutes avec AudioContext.createBuffer(). Une fois mises en mémoire dans un AudioBuffer, les données audio sont transférées dans un AudioBufferSourceNode afin d&apos;être lues.

 Ce type d&apos;objet est conçu pour contenir de petit extraits audio, durant généralement moins de 45s. Pour les sons plus longs, les objets implémentant MediaAudioElementSourceNode sont plus adaptés. La mémoire tampon contient des données au format non entrelacé IEEE 32-bit PCM linéaire, avec une portée nominale comprise entre -1 et +1. S&apos;il y a plusieurs canaux, ils sont stockés dans des mémoires-tampon distinctes."><code>AudioBuffer</code></a>. Les <a href="/fr/docs/Web/API/AudioBuffer" title="L&apos;interface AudioBuffer représente une ressource audio stockée en mémoire, créée à partir d&apos;un fichier audio avec la méthode AudioContext.decodeAudioData(), ou à partir de données brutes avec AudioContext.createBuffer(). Une fois mises en mémoire dans un AudioBuffer, les données audio sont transférées dans un AudioBufferSourceNode afin d&apos;être lues.

 Ce type d&apos;objet est conçu pour contenir de petit extraits audio, durant généralement moins de 45s. Pour les sons plus longs, les objets implémentant MediaAudioElementSourceNode sont plus adaptés. La mémoire tampon contient des données au format non entrelacé IEEE 32-bit PCM linéaire, avec une portée nominale comprise entre -1 et +1. S&apos;il y a plusieurs canaux, ils sont stockés dans des mémoires-tampon distinctes."><code>AudioBuffer</code></a>s sont créés avec la fonction <a href="/fr/docs/Web/API/AudioContext/createBuffer" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createBuffer</code></a> ou retournés par la fonction <a href="/fr/docs/Web/API/AudioContext/decodeAudioData" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.decodeAudioData</code></a> quand elle décode une piste audio avec succès.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createMediaElementSource" title="Pour plus de détails à propos des nœuds source audio des éléments média, constultez la page de référence de MediaElementAudioSourceNode."><code>AudioContext.createMediaElementSource()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/MediaElementAudioSourceNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>MediaElementAudioSourceNode</code></a> associé à <a href="/fr/docs/Web/API/HTMLMediaElement" title="L&apos;interface HTMLMediaElement ajoute à HTMLElement les propriétés et les méthodes nécessaires pour prendre en charge les fonctionnalités de base liées aux médias qui sont communes aux vidéos et aux documents audios. HTMLVideoElement et HTMLAudioElement héritent de cette interface."><code>HTMLMediaElement</code></a>. Il peut être utilisé pour manipuler le son d&apos;éléments <a href="/fr/docs/Web/HTML/Element/video" title="L&apos;élément HTML &lt;video&gt; intègre un contenu vidéo dans un document."><code>&lt;video&gt;</code></a> ou <a href="/fr/docs/Web/HTML/Element/audio" title="L&apos;élément HTML &lt;audio&gt; est utilisé afin d&apos;intégrer un contenu sonore dans un document. Il peut contenir une ou plusieurs sources audio représentées avec l&apos;attribut src ou l&apos;élément &lt;source&gt;. S&apos;il y a plusieurs sources, l&apos;agent utilisateur choisira celle qui convient le mieux."><code>&lt;audio&gt;</code></a>.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createMediaStreamSource" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createMediaStreamSource()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/MediaStreamAudioSourceNode" title="Un MediaElementSourceNode n&apos;a pas d&apos;entrée et une seule sortie. On le créé en utilisant la méthode AudioContext.createMediaStreamSource. Le nombre de canaux de sortie est égal au nombre de canaux de AudioMediaStreamTrack. S&apos;il n&apos;y a pas de media stream valide, alors la sortie sera constituée d&apos;un seul canal silencieux."><code>MediaStreamAudioSourceNode</code></a> associé à un <a href="/fr/docs/Web/API/MediaStream" title="L&apos;interface MediaStream représente le contenu d&apos;un flux de média. Un flux est composé de plusieurs pistes, tel que des pistes vidéos ou audio."><code>MediaStream</code></a> correspondant à un flux audio, qui peut provenir du microphone de l&apos;ordinateur local ou d&apos;autres sources.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createMediaStreamDestination" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createMediaStreamDestination()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/MediaStreamAudioDestinationNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>MediaStreamAudioDestinationNode</code></a> associé à un <a href="/fr/docs/Web/API/MediaStream" title="L&apos;interface MediaStream représente le contenu d&apos;un flux de média. Un flux est composé de plusieurs pistes, tel que des pistes vidéos ou audio."><code>MediaStream</code></a> correspondant à un flux audio, qui peut être stocké dans un fichier local ou envoyé à un autre ordinateur.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createScriptProcessor" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createScriptProcessor()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/ScriptProcessorNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>ScriptProcessorNode</code></a> qui sert à faire du traitement audio directement avec JavaScript.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createStereoPanner" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createStereoPanner()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/StereoPannerNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>StereoPannerNode</code></a> qui permet d&apos;appliquer une panoramique sonore à une source audio.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createAnalyser" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createAnalyser()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/AnalyserNode" title="L&apos; interface AnalyserNode représente un noeud capable de fournir en temps réel des informations d&apos;analyse de la fréquence et du domaine temporel. C&apos;est un AudioNode qui transmet le flux audio inchangé depuis l&apos;entrée vers la sortie, mais permet de capturer les données générées pour les traiter et/ou les visualiser."><code>AnalyserNode</code></a> qui expose les données de temps et de fréquence, et peut être utilisé pour créer des visualisations de données.</dd>
</dl>

<dl>
 <dt><a href="/fr/docs/Web/API/AudioContext/createBiquadFilter" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createBiquadFilter()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/BiquadFilterNode" title="AudioContext.createBiquadFilter()"><code>BiquadFilterNode</code></a>, qui représente un filtre de deuxième niveau, qui combine différents types de filtres de base : fréquences hautes, fréquences basses, passe-bande, etc.</dd>
</dl>

<dl>
 <dt><a href="/fr/docs/Web/API/AudioContext/createChannelMerger" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createChannelMerger()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/ChannelMergerNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>ChannelMergerNode</code></a> qui permet de rassembler les canaux de différents flux audio en un seul flux.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createChannelSplitter" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createChannelSplitter()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/ChannelSplitterNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>ChannelSplitterNode</code></a> utilisé pour accéder aux différents canaux d&apos;un même flux audio et les traiter séparément.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createConvolver" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createConvolver()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/ConvolverNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>ConvolverNode</code></a>, qui permet d&apos;appliquer des effets de convolution à un graphe audio, par exemple un effet de réverb.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createDelay" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createDelay()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/DelayNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>DelayNode</code></a>, utilisé pour retarder le signal audio entrant d&apos;un certain temps. Il est également </dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createDynamicsCompressor" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createDynamicsCompressor()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/DynamicsCompressorNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>DynamicsCompressorNode</code></a> qui permet d&apos;appliquer une compression sur un signal audio.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createGain" title="Un GainNode qui prend en entrée une ou plusieurs sources audio et en sortie un son dont le volume a été ajusté à un niveau indiqué par le paramètre de type a-rate GainNode.gain."><code>AudioContext.createGain()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/GainNode" title="L&apos;interface GainNode représente une variation de volume. Il s&apos;agit d&apos;un AudioNode, c&apos;est un module de traitement audio, qui provoque un gain donné à appliquer à des données d&apos;entrée avant sa propagation à la sortie. Un GainNode a toujours exactement une entrée et une sortie, avec la même quantité de canaux."><code>GainNode</code></a> qui permet de controller le niveau sonore global d&apos;un graphe audio.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createIIRFilter" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createIIRFilter()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/IIRFilterNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>IIRFilterNode</code></a>, qui représente un filtre de second ordre configurable comme différents types de filtres communs.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createOscillator" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createOscillator()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/OscillatorNode" title="On crée un OscillatorNode en utilisant la méthode AudioContext.createOscillator. Il a toujours exactement une sortie, et aucune entrée. Ses propriétés par défaut (voir AudioNode pour la définition) sont :"><code>OscillatorNode</code></a> qui représente une onde périodique. Il génère simplement un son.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createPanner" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createPanner()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/PannerNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>PannerNode</code></a> utilisé pour spatialiser une source audio entrante dans un espace 3D.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createPeriodicWave" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createPeriodicWave()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/PeriodicWave" title="PeriodicWave n&apos;a ni entrée ni sortie; elle doit être créée avec AudioContext.createPeriodicWave() et être assignée à un OscillatorNode avec OscillatorNode.setPeriodicWave()."><code>PeriodicWave</code></a>, utilisé pour définir une onde périodique qui peut être utilisée pour contrôler la sortie d&apos;un <a href="/fr/docs/Web/API/OscillatorNode" title="On crée un OscillatorNode en utilisant la méthode AudioContext.createOscillator. Il a toujours exactement une sortie, et aucune entrée. Ses propriétés par défaut (voir AudioNode pour la définition) sont :"><code>OscillatorNode</code></a>.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createWaveShaper" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createWaveShaper()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/WaveShaperNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>WaveShaperNode</code></a>, qui permet d&apos;implémenter des effets de distorsion non linéaires.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createAudioWorker" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createAudioWorker()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/AudioWorkerNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioWorkerNode</code></a>, qui permet d&apos;interagir avec un thread web worker afin de générer, traiter, ou analyser le son directement. Ajouté à la spec le 29 août 2014, mais encore implémenté par aucun des navigateurs à ce jour.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/decodeAudioData" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.decodeAudioData()</code></a></dt>
 <dd>Décode de façon asynchrone les données d&apos;un fichier audio contenues dans un objet <a href="/fr/docs/Web/API/ArrayBuffer" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>ArrayBuffer</code></a>. Dans ce cas, le ArrayBuffer est en général chargé depuis un attribut de réponse <a href="/fr/docs/Web/API/XMLHttpRequest" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>XMLHttpRequest</code></a> quand l&apos;attribut <code>responseType</code> est <code>arraybuffer</code>. Cette méthode ne fonctionne que sur des fichiers complets, pas sur des fragments de fichiers.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/resume" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.resume()</code></a></dt>
 <dd>Reprend le défilement du temps dans un contexte audio où il a précédemment été suspendu.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/suspend" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.suspend()</code></a></dt>
 <dd>Suspend le défilement du temps dans un contexte audio, empêchant de façon temporaire l&apos;accès au hardware audio, et réduisant par là l&apos;utilisation du CPU et de la batterie.</dd>
</dl>

<h2 id="Méthodes_obsolètes">Méthodes obsolètes</h2>

<dl>
 <dt><a href="/fr/docs/Web/API/AudioContext/createJavaScriptNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createJavaScriptNode()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/JavaScriptNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>JavaScriptNode</code></a>, utilisé pour un traitement audio directement en JavaScript. Cette méthode est obsolète, et a été remplacée par <a href="/fr/docs/Web/API/AudioContext/createScriptProcessor" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createScriptProcessor()</code></a>.</dd>
 <dt><a href="/fr/docs/Web/API/AudioContext/createWaveTable" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createWaveTable()</code></a></dt>
 <dd>Crée un objet <a href="/fr/docs/Web/API/WaveTableNode" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>WaveTableNode</code></a>, utilisé pour définir une onde audio périodique. Cette méthode est obsolète, et a été remplacée par <a href="/fr/docs/Web/API/AudioContext/createPeriodicWave" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>AudioContext.createPeriodicWave()</code></a>.</dd>
</dl>

<h2 id="Exemples">Exemples</h2>

<p>Déclaration basique d&apos;un audio context :</p>

<pre><code>var contexteAudio = new AudioContext;</code></pre>

<p>Variante avec gestion de la compatibilité navigateur:</p>

<pre><code>var AudioContext = window.AudioContext || window.webkitAudioContext;
var contexteAudio = new AudioContext();

var oscillatorNode = contexteAudio.createOscillator();
var gainNode = contexteAudio.createGain();
var finish = contexteAudio.destination;
// etc.</code></pre>

<h2 id="Spécifications">Spécifications</h2>

<table class="standard-table">
 <tbody>
  <tr>
   <th scope="col">Spécification</th>
   <th scope="col">Statut</th>
   <th scope="col">Commentaire</th>
  </tr>
  <tr>
   <td><a lang="en" href="https://webaudio.github.io/web-audio-api/#AudioContext-section" class="external" hreflang="en">Web Audio API<br><small lang="fr">La définition de &apos;AudioNode&apos; dans cette spécification.</small></a></td>
   <td><span class="spec-WD">Version de travail</span></td>
   <td> </td>
  </tr>
 </tbody>
</table>

<h2 id="Compatibilité_des_navigateurs">Compatibilité des navigateurs</h2>

<div><div class="warning notecard"><strong><a href="https://github.com/mdn/browser-compat-data">Nous convertissons les données de compatibilité dans un format JSON</a></strong>.
            Ce tableau de compatibilité utilise encore l&apos;ancien format
            car nous n&apos;avons pas encore converti les données qu&apos;il contient.
            <strong><a href="/fr/docs/MDN/Contribute/Structures/Compatibility_tables">Vous pouvez nous aider en contribuant !</a></strong></div>

<div class="htab">
    <a id="AutoCompatibilityTable" name="AutoCompatibilityTable"></a>
    <ul>
        <li class="selected"><a>Ordinateur</a></li>
        <li><a>Mobile</a></li>
    </ul>
</div></div>

<div id="compat-desktop">
<table class="compat-table">
 <tbody>
  <tr>
   <th>Fonctionnalité</th>
   <th>Chrome</th>
   <th>Edge</th>
   <th>Firefox (Gecko)</th>
   <th>Internet Explorer</th>
   <th>Opera</th>
   <th>Safari (WebKit)</th>
  </tr>
  <tr>
   <td>Basic support</td>
   <td>10.0<span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/fr/docs/Web/Guide/Prefixes" title="Le nom de cette fonctionnalité est préfixé par &apos;webkit&apos; car ce navigateur la considère expérimentale">webkit</a></span><br>
    35</td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><a href="/en-US/Firefox/Releases/25" title="Sorti le 2013-10-29.">25.0</a> (25.0) </td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td>15.0<span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/fr/docs/Web/Guide/Prefixes" title="Le nom de cette fonctionnalité est préfixé par &apos;webkit&apos; car ce navigateur la considère expérimentale">webkit</a></span><br>
    22</td>
   <td>6.0<span class="prefixBox prefixBoxInline notecard inline" title="prefix"><a href="/fr/docs/Web/Guide/Prefixes" title="Le nom de cette fonctionnalité est préfixé par &apos;webkit&apos; car ce navigateur la considère expérimentale">webkit</a></span></td>
  </tr>
  <tr>
   <td><code>createStereoPanner()</code></td>
   <td>42.0</td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><a href="/en-US/Firefox/Releases/37" title="Sorti le 2015-04-07.">37.0</a> (37.0) </td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
  </tr>
  <tr>
   <td><code>onstatechange</code>, <code>state</code>, <code>suspend()</code>, <code>resume()</code></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><a href="/en-US/Firefox/Releases/40" title="Sorti le 2015-08-11.">40.0</a> (40.0)</td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td>8.0</td>
  </tr>
  <tr>
   <td><code>createConstantSource()</code></td>
   <td>56.0</td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><a href="/en-US/Firefox/Releases/52" title="Sorti le 2017-03-07.">52</a> (52)</td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td>43</td>
   <td><span style="color: #f00;">Pas de support</span></td>
  </tr>
  <tr>
   <td>Non préfixé</td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td> </td>
   <td> </td>
   <td> </td>
   <td> </td>
  </tr>
 </tbody>
</table>
</div>

<div id="compat-mobile">
<table class="compat-table">
 <tbody>
  <tr>
   <th>Fonctionnalité</th>
   <th>Android Webview</th>
   <th>Edge</th>
   <th>Firefox Mobile (Gecko)</th>
   <th>Firefox OS</th>
   <th>IE Mobile</th>
   <th>Opera Mobile</th>
   <th>Safari Mobile</th>
   <th>Chrome for Android</th>
  </tr>
  <tr>
   <td>Support basique</td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><a href="/en-US/Firefox/Releases/37" title="Sorti le 2015-04-07.">37.0</a> (37.0) </td>
   <td>2.2</td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
  </tr>
  <tr>
   <td><code>createStereoPanner()</code></td>
   <td>42.0</td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td>42.0</td>
  </tr>
  <tr>
   <td><code>onstatechange</code>, <code>state</code>, <code>suspend()</code>, <code>resume()</code></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
  </tr>
  <tr>
   <td><code>createConstantSource()</code></td>
   <td>56.0</td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td>52.0 (52)</td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td><span style="color: #f00;">Pas de support</span></td>
   <td>56.0</td>
  </tr>
  <tr>
   <td>Non préfixé</td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td>43</td>
   <td><span style="color: rgb(255, 153, 0);" title="Compatibility unknown; please update this.">?</span></td>
   <td><span style="color: #888;" title="Veuillez mettre à jour avec la version minimale du support">(Oui)</span></td>
  </tr>
 </tbody>
</table>
</div>

<h2 id="Voir_aussi">Voir aussi</h2>

<ul>
 <li><a href="https://developer.mozilla.org/fr/docs/Web_Audio_API/Using_Web_Audio_API">Utiliser la Web Audio API</a></li>
 <li><a href="/fr/docs/Web/API/OfflineAudioContext" title="Cette documentation n&apos;a pas encore été rédigée, vous pouvez aider en contribuant !"><code>OfflineAudioContext</code></a></li>
</ul>
