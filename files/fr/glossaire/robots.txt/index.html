---
title: Robots.txt
slug: Glossaire/Robots.txt
tags:
  - Glossaire
  - Infrastructure
translation_of: Glossary/Robots.txt
---
<p>Robots.txt est un fichier qui est habituellement placé à la racine d'un site web. Il détermine si les <a href="/fr/docs/Glossaire/Robot_d_indexation" class="glossaryLink" title="robots d'indexation : Un robot d'indexation est un programme, souvent appelé bot ou robot, qui parcourt de manière systématique le Web pour collecter des données à partir des pages web. Les moteurs de recherche utilisent généralement des robots d'indexation pour construire leurs index.">robots d'indexation</a> ont ou non l'autorisation d'accéder au site web.</p>

<p>Par exemple, l'administrateur d'un site peut interdire aux robots d'indexation de parcourir un certain dossier (et tous les fichiers contenus à l'intérieur) ou de parcourir un fichier spécifique, généralement pour empêcher ces fichiers d'être indexés par d'autres moteurs de recherche.</p>

<h2 id="Pour_approfondir">Pour approfondir</h2>

<h3 id="Culture_générale">Culture générale</h3>

<ul>
 <li><a href="https://fr.wikipedia.org/wiki/Protocole_d'exclusion_des_robots" title="Robots.txt">Robots.txt</a> sur Wikipédia</li>
</ul>
